{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SdedseitehCB",
    "outputId": "04626130-7a08-4105-cb1e-1960d83444c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna==3.6.1\n",
      "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from optuna==3.6.1) (1.17.2)\n",
      "Requirement already satisfied: colorlog in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from optuna==3.6.1) (6.10.1)\n",
      "Requirement already satisfied: numpy in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from optuna==3.6.1) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from optuna==3.6.1) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from optuna==3.6.1) (2.0.44)\n",
      "Requirement already satisfied: tqdm in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from optuna==3.6.1) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from optuna==3.6.1) (6.0.3)\n",
      "Requirement already satisfied: Mako in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from alembic>=1.5.0->optuna==3.6.1) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from alembic>=1.5.0->optuna==3.6.1) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from sqlalchemy>=1.3.0->optuna==3.6.1) (3.2.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from Mako->alembic>=1.5.0->optuna==3.6.1) (3.0.3)\n",
      "Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "Installing collected packages: optuna\n",
      "  Attempting uninstall: optuna\n",
      "    Found existing installation: optuna 4.6.0\n",
      "    Uninstalling optuna-4.6.0:\n",
      "      Successfully uninstalled optuna-4.6.0\n",
      "Successfully installed optuna-3.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna==3.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "DYe5jnNwmZQ1"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "from token import SEMI\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "m1lgonWEzgMJ"
   },
   "outputs": [],
   "source": [
    "# @title Setup Logging\n",
    "def setup_logging(log_path: Path):\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(name)s %(lineno)d - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_path, mode=\"w\", encoding=\"utf-8-sig\"),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "DI9hgABw3nCh"
   },
   "outputs": [],
   "source": [
    "# @title Build Foto Mes\n",
    "def build_foto_mes(start_foto_mes: int, end_foto_mes: int, list_of_foto_mes_to_avoid: list[int] = None) -> list[int]:\n",
    "    if list_of_foto_mes_to_avoid is None:\n",
    "        list_of_foto_mes_to_avoid = []\n",
    "\n",
    "    result = []\n",
    "    current_year = start_foto_mes // 100\n",
    "    current_month = start_foto_mes % 100\n",
    "\n",
    "    end_year = end_foto_mes // 100\n",
    "    end_month = end_foto_mes % 100\n",
    "\n",
    "    while True:\n",
    "        current_foto_mes = current_year * 100 + current_month\n",
    "\n",
    "        if current_foto_mes > end_foto_mes:\n",
    "            break\n",
    "\n",
    "        if current_foto_mes not in list_of_foto_mes_to_avoid:\n",
    "            result.append(current_foto_mes)\n",
    "\n",
    "        current_month += 1\n",
    "        if current_month > 12:\n",
    "            current_month = 1\n",
    "            current_year += 1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5K0uJcq-dyPi"
   },
   "outputs": [],
   "source": [
    "# @title Drop Columns\n",
    "def drop_columns(df : pl.DataFrame):\n",
    "\n",
    "    col_drops = ['mprestamos_personales','cprestamos_personales']\n",
    "\n",
    "    if \"Master_Finiciomora\" in df.columns:\n",
    "      col_drops.append(\"Master_Finiciomora\")\n",
    "\n",
    "    df = df.drop(col_drops)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "c4WXDjEtc1dV"
   },
   "outputs": [],
   "source": [
    "# @title Config\n",
    "CONFIG = {\n",
    "    \"STUDY_NAME\": \"competencia-03-exp2-rus\",\n",
    "    \"BUCKETS\": \"/home/tomas_freilij/buckets\",\n",
    "    \"BUCKET_ORIGIN\": \"b1\",\n",
    "    \"BUCKET_TARGET\": \"b2\",\n",
    "    \"SEMILLA\": [100, 420029, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400, 2500],\n",
    "    \"MES_TRAIN_FLOOR\": 202101,\n",
    "    \"MES_TRAIN_CEILING\": 202103,\n",
    "    \"MES_TO_DROP\": [202006],\n",
    "    \"MES_VALIDACION\": 202104,\n",
    "    \"MES_TEST\": 202105,\n",
    "    \"FINAL_TRAIN_FLOOR\": 201901,\n",
    "    \"FINAL_TRAIN_CEILING\": 202107,\n",
    "    \"FINAL_PREDICT\": 202109,\n",
    "    \"GANANCIA_ACIERTO\": 780000,\n",
    "    \"COSTO_ESTIMULO\": 20000,\n",
    "    \"RUN_BAYESIAN_OPTIMIZATION\": False,\n",
    "    \"UNDERSAMPLING_FRACTION\": 0.1,\n",
    "    \"IS_EXPERIMENTO\": False,\n",
    "    \"N_TRIALS\": 30,\n",
    "    \"TEST\" : False,\n",
    "    \"SUFIX\": \"us-0-1-rus\",\n",
    "    \"IS_RANDOM_UNDERSAMPLING\": False\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "form",
    "id": "RVcmsk57zbng"
   },
   "outputs": [],
   "source": [
    "# @title Modelos y Log Directory\n",
    "bucket_target = os.path.join(CONFIG[\"BUCKETS\"], CONFIG[\"BUCKET_TARGET\"])\n",
    "modelos_directory = os.path.join(bucket_target, \"modelos\")\n",
    "log_directory = os.path.join(bucket_target, \"log\")\n",
    "\n",
    "os.makedirs(log_directory, exist_ok=True)\n",
    "os.makedirs(modelos_directory, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "log_dir = Path(CONFIG[\"BUCKETS\"]) / CONFIG[\"BUCKET_TARGET\"] / \"log\"\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "log_path = log_dir / f\"log_fe_{timestamp}.log\"\n",
    "\n",
    "logger = setup_logging(log_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tWCDwubygSjn"
   },
   "outputs": [],
   "source": [
    "# @title Undersample DF\n",
    "def undersample_df(df: pl.DataFrame, fraction, is_random_undersampling: bool = False) -> pl.DataFrame:\n",
    "\n",
    "  if is_random_undersampling:\n",
    "    logger.info(f\"Performing random undersampling with fraction (proportion to KEEP): {fraction}, DF shape: {df.shape}\")\n",
    "    # 'CONTINUA' is the majority, 'BAJA+1' and 'BAJA+2' are minorities\n",
    "    df_minority = df.filter(pl.col(\"clase_ternaria\").is_in([\"BAJA+1\", \"BAJA+2\"])) # Or ['BAJA+1', 'BAJA+2']\n",
    "    df_majority = df.filter(pl.col(\"clase_ternaria\") == \"CONTINUA\")\n",
    "\n",
    "    # `fraction` represents the proportion of the majority class to KEEP.\n",
    "    if fraction >= 1.0 or df_majority.shape[0] == 0: # Keep all if fraction is 100% or no majority samples\n",
    "        df_majority_sampled = df_majority\n",
    "    else:\n",
    "        # Sample the majority class to keep `fraction` of its rows\n",
    "        df_majority_sampled = df_majority.sample(fraction=fraction, seed=1000, shuffle=True)\n",
    "\n",
    "    df_filtered = pl.concat([df_minority, df_majority_sampled])\n",
    "    logger.info(f\"DF shape after random undersampling: {df_filtered.shape}\")\n",
    "\n",
    "  else:\n",
    "    logger.info(f\"Performing client-based undersampling with fraction (proportion to KEEP): {fraction}, DF shape: {df.shape}\")\n",
    "    clientes_solo_continuas = (\n",
    "        df.group_by(\"numero_de_cliente\")\n",
    "        .agg(\n",
    "            n_bajas=pl.col(\"clase_ternaria\")\n",
    "            .is_in([\"BAJA+1\", \"BAJA+2\"])\n",
    "            .sum()\n",
    "        )\n",
    "        .filter(pl.col(\"n_bajas\") == 0)\n",
    "    )\n",
    "\n",
    "    # Sample (1 - fraction) of 'solo_continuas' clients to REMOVE them, effectively keeping 'fraction' of them.\n",
    "    clientes_solo_continuas_undersampled = clientes_solo_continuas.sample(\n",
    "        fraction=1 - fraction, seed=1000\n",
    "    )\n",
    "\n",
    "    df_filtered = df.filter(\n",
    "        ~pl.col('numero_de_cliente').is_in(\n",
    "            clientes_solo_continuas_undersampled[\"numero_de_cliente\"]\n",
    "        )\n",
    "    )\n",
    "    logger.info(f\"DF shape after client-based undersampling: {df_filtered.shape}\")\n",
    "\n",
    "  return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "id": "C_PUMSVajqZK"
   },
   "outputs": [],
   "source": [
    "# @title Clientes Sin bajas\n",
    "def clientes_sin_bajas(df: pl.DataFrame) -> pl.DataFrame:\n",
    "  logger.info(f\"Clientes sin bajas\")\n",
    "\n",
    "  clientes_sin_bajas = (\n",
    "      df.group_by(\"numero_de_cliente\")\n",
    "      .agg(\n",
    "          n_bajas=pl.col(\"clase_ternaria\")\n",
    "          .is_in([\"BAJA+1\", \"BAJA+2\"])\n",
    "          .sum()\n",
    "      )\n",
    "      .filter(pl.col(\"n_bajas\") == 0)\n",
    "  )\n",
    "\n",
    "  logger.info(f\"Cantidad de clientes sin bajas: {clientes_sin_bajas.shape}\")\n",
    "  return clientes_sin_bajas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6mI03FVZgb4g"
   },
   "outputs": [],
   "source": [
    "# @title Clase Binaria\n",
    "def generate_clase_binaria(df : pl.DataFrame, is_prediction = False):\n",
    "    ternarias_baja = []\n",
    "    if is_prediction:\n",
    "      ternarias_baja = [\"BAJA+2\"]\n",
    "    else:\n",
    "      ternarias_baja = [\"BAJA+2\", \"BAJA+1\"]\n",
    "\n",
    "    df = df.with_columns(pl.lit(0).alias('clase_binaria'))\n",
    "\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col('clase_ternaria').is_in(ternarias_baja)).then(pl.lit(1)).otherwise(pl.lit(0)).alias('clase_binaria')\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellView": "form",
    "id": "Zirt-GdAhuvs"
   },
   "outputs": [],
   "source": [
    "# @title Lectura de Datasets\n",
    "\n",
    "file_comp = Path(CONFIG[\"BUCKETS\"]) / CONFIG[\"BUCKET_ORIGIN\"] / \"competencia_03_fe.csv\"\n",
    "\n",
    "df = pl.read_csv(file_comp, infer_schema_length=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spmH7y4lDMuY",
    "outputId": "1776c956-8ded-46f8-f59c-69e11b20088d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 22:47:55,273 - INFO - __main__ 5 - DF Shape : (4729949, 774)\n",
      "/tmp/ipykernel_5534/624196385.py:6: DeprecationWarning: `GroupBy.count` was renamed; use `GroupBy.len` instead\n",
      "  logger.info(f\"DF Foto_mes : {df_ternaria.group_by(\"clase_ternaria\", \"foto_mes\").count()}\")\n",
      "2025-12-03 22:48:01,755 - INFO - __main__ 6 - DF Foto_mes : shape: (92, 3)\n",
      "┌────────────────┬──────────┬────────┐\n",
      "│ clase_ternaria ┆ foto_mes ┆ count  │\n",
      "│ ---            ┆ ---      ┆ ---    │\n",
      "│ str            ┆ i64      ┆ u32    │\n",
      "╞════════════════╪══════════╪════════╡\n",
      "│ BAJA+2         ┆ 201909   ┆ 570    │\n",
      "│ BAJA+1         ┆ 202012   ┆ 618    │\n",
      "│ BAJA+1         ┆ 202008   ┆ 475    │\n",
      "│ BAJA+1         ┆ 201910   ┆ 581    │\n",
      "│ BAJA+1         ┆ 202003   ┆ 166    │\n",
      "│ …              ┆ …        ┆ …      │\n",
      "│ CONTINUA       ┆ 202004   ┆ 148432 │\n",
      "│ CONTINUA       ┆ 202008   ┆ 155497 │\n",
      "│ CONTINUA       ┆ 201906   ┆ 127453 │\n",
      "│ CONTINUA       ┆ 201905   ┆ 126016 │\n",
      "│ BAJA+1         ┆ 202009   ┆ 496    │\n",
      "└────────────────┴──────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "if CONFIG[\"TEST\"]:\n",
    "  df_crudo = df_crudo.filter(pl.col(\"foto_mes\").is_in(build_foto_mes(CONFIG[\"MES_TRAIN_FLOOR\"],CONFIG[\"FINAL_PREDICT\"]+2)))\n",
    "df_ternaria = df\n",
    "\n",
    "logger.info(f\"DF Shape : {df_ternaria.shape}\")\n",
    "logger.info(f\"DF Foto_mes : {df_ternaria.group_by(\"clase_ternaria\", \"foto_mes\").count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kOYipD6lkPV6"
   },
   "outputs": [],
   "source": [
    "df = drop_columns(df_ternaria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ySRIUWK3kQf6"
   },
   "outputs": [],
   "source": [
    "df_optimizacion = df.filter(pl.col('foto_mes').is_in(build_foto_mes(CONFIG[\"MES_TRAIN_FLOOR\"],CONFIG[\"MES_TEST\"],CONFIG[\"MES_TO_DROP\"])))\n",
    "df_optimizacion = generate_clase_binaria(df_optimizacion, is_prediction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TruOUymV-1-v"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 22:48:08,269 - INFO - __main__ 21 - Performing client-based undersampling with fraction (proportion to KEEP): 0.1, DF shape: (814126, 772)\n",
      "/tmp/ipykernel_5534/423577188.py:37: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  df_filtered = df.filter(\n",
      "2025-12-03 22:48:10,937 - INFO - __main__ 42 - DF shape after client-based undersampling: (98506, 772)\n"
     ]
    }
   ],
   "source": [
    "df_optimizacion = undersample_df(df_optimizacion, CONFIG[\"UNDERSAMPLING_FRACTION\"], CONFIG[\"IS_RANDOM_UNDERSAMPLING\"])\n",
    "\n",
    "df_optimizacion_val = df_optimizacion.filter(pl.col('foto_mes') == CONFIG[\"MES_VALIDACION\"])\n",
    "df_optimizacion_train = df_optimizacion.filter(pl.col('foto_mes').is_in(build_foto_mes(CONFIG[\"MES_TRAIN_FLOOR\"],CONFIG[\"MES_VALIDACION\"]-1,CONFIG[\"MES_TO_DROP\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NYyVCarftWe5"
   },
   "outputs": [],
   "source": [
    "target_class = [\"clase_ternaria\", \"clase_binaria\", \"numero_de_cliente\"]\n",
    "\n",
    "cols_train = df.columns\n",
    "\n",
    "for c in ['numero_de_cliente', 'clase_binaria','foto_mes',\"clase_ternaria\"]:\n",
    "  if c in cols_train:\n",
    "    cols_train.remove(c)\n",
    "\n",
    "#df_optimizacion_val_with_target = df_optimizacion_val.select(['numero_de_cliente', 'clase_binaria','foto_mes',\"clase_ternaria\"])\n",
    "#df_optimizacion_train_with_target = df_optimizacion_train.select(['numero_de_cliente', 'clase_binaria','foto_mes',\"clase_ternaria\"])\n",
    "\n",
    "#df_optimizacion_val = df_optimizacion_val.drop(['numero_de_cliente', 'clase_binaria','foto_mes',\"clase_ternaria\"])\n",
    "#df_optimizacion_train = df_optimizacion_train.drop(['numero_de_cliente', 'clase_binaria','foto_mes',\"clase_ternaria\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MiIoHuQbgN2Q"
   },
   "outputs": [],
   "source": [
    "# @title Build Predictions\n",
    "def build_predictions(modelos, dataset : pl.DataFrame, cols_train : list) -> pl.DataFrame:\n",
    "  predicciones = {}\n",
    "\n",
    "\n",
    "  df_to_predict = dataset.select(cols_train)\n",
    "  dataset_np = df_to_predict.to_numpy()\n",
    "\n",
    "  for seed,model in modelos.items():\n",
    "    predictions = model.predict(dataset_np)\n",
    "    predicciones[seed] = predictions\n",
    "\n",
    "  mean_predictions = np.mean(list(predicciones.values()), axis=0)\n",
    "  return pl.DataFrame({'numero_de_cliente': dataset[\"numero_de_cliente\"], 'Predicted': mean_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "RV0oFZJWocEu"
   },
   "outputs": [],
   "source": [
    "# @title Calcular Cantidad Envíos para la máxima ganancia\n",
    "def calcular_cantidad_envios(y_pred : pl.DataFrame, y_true : pl.DataFrame) -> float:\n",
    "    df = y_pred.join(y_true, on=\"numero_de_cliente\")\n",
    "\n",
    "    df_ordenado = df.sort(\"Predicted\", descending=True)\n",
    "\n",
    "    # Ganancia individual por fila, cast to Float64 to prevent potential overflow\n",
    "    df_ordenado = df_ordenado.with_columns([\n",
    "        pl.when(pl.col(\"clase_binaria\") == 1)\n",
    "          .then(pl.lit(CONFIG[\"GANANCIA_ACIERTO\"]).cast(pl.Float64))\n",
    "          .otherwise(pl.lit(-CONFIG[\"COSTO_ESTIMULO\"]).cast(pl.Float64))\n",
    "          .alias(\"ganancia_individual\")\n",
    "    ])\n",
    "\n",
    "    # Ganancia acumulada\n",
    "    df_ordenado = df_ordenado.with_columns([\n",
    "        pl.col(\"ganancia_individual\").cum_sum().alias(\"ganancia_acumulada\")\n",
    "    ])\n",
    "\n",
    "    # Obtener ganancia maxima\n",
    "    ganancia_maxima = df_ordenado.select(pl.col(\"ganancia_acumulada\").max()).item()\n",
    "\n",
    "    # Find the index of the first occurrence of the maximum cumulative gain\n",
    "    idx_max_ganancia = df_ordenado[\"ganancia_acumulada\"].arg_max()\n",
    "\n",
    "    # The number of sends is the index + 1 (since index is 0-based)\n",
    "    cantidad_envios_real = idx_max_ganancia + 1\n",
    "\n",
    "    return \"calcular_cantidad_envios\", float(ganancia_maxima), cantidad_envios_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "eVQTZz0IB53t"
   },
   "outputs": [],
   "source": [
    "# @title Función de Evaluación de Ganancia sin n_envios (A REVISION)\n",
    "def lgb_gan_eval(y_pred, data: lgb.Dataset):\n",
    "  label = data.get_label()\n",
    "\n",
    "  ganancia = np.where(label == 1, CONFIG[\"GANANCIA_ACIERTO\"], 0) - np.where(\n",
    "      label < 1.00002, CONFIG[\"COSTO_ESTIMULO\"], 0\n",
    "  )\n",
    "\n",
    "  ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "  ganancia = np.cumsum(ganancia)\n",
    "\n",
    "  return \"lgb_gan_eval\", float(np.max(ganancia)), True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CuSdOSvFgvSq",
    "outputId": "a2eafc5d-2dce-429f-a0fe-c2d8cc82afaf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-03 23:07:34,466] Using an existing study with name 'competencia-03-exp2-rus' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial) -> float:\n",
    "\n",
    "  num_leaves = trial.suggest_int('num_leaves', 30, 200)\n",
    "  learning_rate = trial.suggest_float('learning_rate', 0.01, 0.1)\n",
    "  min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 100, 500)\n",
    "  feature_fraction = trial.suggest_float('feature_fraction', 0.1, 1.0)\n",
    "  max_bin = trial.suggest_int('max_bin', 30, 200, step=10)\n",
    "  num_iterations = trial.suggest_int('num_iterations', 500, 2000)\n",
    "\n",
    "  params = {\n",
    "      'objective': 'binary',\n",
    "      'metric': 'custom',\n",
    "      'boosting_type': 'gbdt',\n",
    "      'first_metric_only': True,\n",
    "      'boost_from_average': True,\n",
    "      'feature_pre_filter': False,\n",
    "      'max_bin': max_bin,\n",
    "      'num_leaves': num_leaves,\n",
    "      'learning_rate': learning_rate,\n",
    "      'min_data_in_leaf': min_data_in_leaf,\n",
    "      'feature_fraction': feature_fraction,\n",
    "      'seed': CONFIG[\"SEMILLA\"][1],\n",
    "      'verbose': -1,\n",
    "      'num_iterations': num_iterations\n",
    "      }\n",
    "\n",
    "  train_data = lgb.Dataset(df_optimizacion_train.select(cols_train).to_numpy(),\n",
    "                            label=df_optimizacion_train[\"clase_binaria\"].to_numpy())\n",
    "\n",
    "  val_data = lgb.Dataset(df_optimizacion_val.select(cols_train).to_numpy(),\n",
    "                           label=df_optimizacion_val[\"clase_binaria\"].to_numpy())\n",
    "  modelos = {}\n",
    "\n",
    "  for seed in CONFIG[\"SEMILLA\"]:\n",
    "    params[\"seed\"] = seed\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[val_data],\n",
    "        feval = lgb_gan_eval,\n",
    "        callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=int(50 + 5 / params['learning_rate']), verbose=False)\n",
    "            ]\n",
    "\n",
    "      )\n",
    "    modelos[seed] = model\n",
    "\n",
    "    optimization_predictions = build_predictions(modelos, df_optimizacion_val, cols_train)\n",
    "    print(f\"Val target: {df_optimizacion_val[\"clase_binaria\"].value_counts()}\")\n",
    "    df_test = generate_clase_binaria(df.filter(pl.col(\"foto_mes\") == CONFIG[\"MES_TEST\"]),is_prediction = True)\n",
    "    _,ganancia_total, n_envios_test = calcular_cantidad_envios(optimization_predictions, df_test)\n",
    "    print(f\"Resultado: {ganancia_total}, {n_envios_test}\")\n",
    "    logger.info(f\"Finished Trial {trial.number}: Ganancia = {ganancia_total}\")\n",
    "\n",
    "    trial.set_user_attr(\"best_iteration\", model.best_iteration)\n",
    "\n",
    "    return ganancia_total\n",
    "\n",
    "\n",
    "# SE INTENTA RECUPERAR UN ESTUDIO O SE INICIA UNO NUEVO\n",
    "#storage_name = f\"sqlite:////{os.path.join(BUCKETS, BUCKET_TARGET,STUDY_NAME)}.db\"\n",
    "db_file_path = os.path.join(modelos_directory, CONFIG[\"STUDY_NAME\"] + \".db\")\n",
    "storage_name = f\"sqlite:///{db_file_path}\"\n",
    "study_name = CONFIG[\"STUDY_NAME\"]\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "# HAY UN FLAG EN EL CONFIG PARA EVITAR CORRER LA OPTIMIZACION SIEMPRE\n",
    "if CONFIG[\"RUN_BAYESIAN_OPTIMIZATION\"]:\n",
    "  logger.info(f\"Run Optimization with {CONFIG[\"N_TRIALS\"]}\")\n",
    "  study.optimize(lambda trial: objective(trial), n_trials=CONFIG[\"N_TRIALS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ctajKctghp4t"
   },
   "outputs": [],
   "source": [
    "# @title Build and Save Model\n",
    "## SE ARMA EL MODELO Y DE SER POSIBLE SE PERSISTE PARA PODER USARLO PARA OTRA PREDICCION.\n",
    "def build_and_save_or_load_models(study, semillas : list, train_dataset : pl.DataFrame, undersampling_fraction) -> dict:\n",
    "\n",
    "  if undersampling_fraction == None:\n",
    "    raise RuntimeError(f\"Undersampling Fraction {undersampling_fraction} no puede ser None\")\n",
    "\n",
    "  modelos = {}\n",
    "\n",
    "  all_models_exist = True\n",
    "  for seed in CONFIG[\"SEMILLA\"]:\n",
    "    model_name = f\"lgb_predict_{seed}_{CONFIG[\"SUFIX\"]}.txt\"\n",
    "    model_file_path = os.path.join(modelos_directory, model_name)\n",
    "    if not os.path.exists(model_file_path):\n",
    "      all_models_exist = False\n",
    "      break\n",
    "\n",
    "  if all_models_exist:\n",
    "    logger.info(\"All predict models exist. Loading them.\")\n",
    "    for seed in CONFIG[\"SEMILLA\"]:\n",
    "        model_name = f\"lgb_predict_{seed}_{CONFIG[\"SUFIX\"]}.txt\"\n",
    "        model_file_path = os.path.join(modelos_directory, model_name)\n",
    "        modelos[seed] = lgb.Booster(model_file=model_file_path)\n",
    "  else:\n",
    "    logger.info(\"Train Predict Models (some models were missing or not all present)\")\n",
    "    train_dataset_np = train_dataset.select(cols_train).to_numpy()\n",
    "    y_target_np = train_dataset[\"clase_binaria\"].to_numpy()\n",
    "\n",
    "    train_data = lgb.Dataset(train_dataset_np,\n",
    "                                label=y_target_np,\n",
    "                                feature_name=cols_train)\n",
    "\n",
    "    if len(study.trials) == 0:\n",
    "      raise RuntimeError(\"No trials found in study. Run optimization first.\")\n",
    "\n",
    "    best_params = study.best_trial.params.copy()\n",
    "    best_iter = study.best_trial.user_attrs.get(\"best_iter\", 110)\n",
    "    best_params[\"min_data_in_leaf\"] = int(best_params[\"min_data_in_leaf\"] * 100 / undersampling_fraction)\n",
    "    logger.info(f\"Best Params: {best_params}\")\n",
    "    for seed in semillas:\n",
    "\n",
    "      params = {\n",
    "              'objective': 'binary',\n",
    "                'metric': 'custom',\n",
    "                'boosting_type': 'gbdt',\n",
    "                'first_metric_only': True,\n",
    "                'boost_from_average': True,\n",
    "                'feature_pre_filter': False,\n",
    "                'seed': seed,\n",
    "                'verbose': -1,\n",
    "                **best_params\n",
    "          }\n",
    "\n",
    "      model = lgb.train(params, train_data, num_boost_round=best_iter)\n",
    "\n",
    "      modelos[seed] = model\n",
    "      model.save_model(os.path.join(modelos_directory,f\"lgb_predict_{seed}_{CONFIG[\"SUFIX\"]}.txt\"))\n",
    "\n",
    "  return modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "8C2JX8HPgRPv"
   },
   "outputs": [],
   "source": [
    "# @title Build Final Predictions\n",
    "\n",
    "\n",
    "def build_final_predictions(predict_models, df_predict, n_envios, cols_train):\n",
    "  mean_predictions = build_predictions(predict_models, df_predict, cols_train)\n",
    "  sorted_mean_predictions = mean_predictions.sort('Predicted', descending=True)\n",
    "  final_predictions = sorted_mean_predictions.with_columns(\n",
    "        (pl.arange(0, sorted_mean_predictions.height) < n_envios)\n",
    "        .cast(pl.Int8)\n",
    "        .alias(\"Predicted\")\n",
    "    )\n",
    "\n",
    "  return final_predictions.select([\"numero_de_cliente\", \"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cellView": "form",
    "id": "SM4t8qlRhPjm"
   },
   "outputs": [],
   "source": [
    "# @title Forzar N Envios\n",
    "def forzar_n_envios(y_pred : pl.DataFrame, y_true : pl.DataFrame, n_envios: int) -> tuple[float, int]:\n",
    "    df_eval = y_pred.join(y_true, on=\"numero_de_cliente\")\n",
    "\n",
    "    df_ordenado = df_eval.sort(\"Predicted\", descending=True)\n",
    "\n",
    "    # Ganancia individual por fila, cast to Float64 to prevent potential overflow\n",
    "    df_ordenado = df_ordenado.with_columns([\n",
    "        pl.when(pl.col(\"clase_binaria\") == 1)\n",
    "          .then(pl.lit(CONFIG[\"GANANCIA_ACIERTO\"]).cast(pl.Float64))\n",
    "          .otherwise(pl.lit(-CONFIG[\"COSTO_ESTIMULO\"]).cast(pl.Float64))\n",
    "          .alias(\"ganancia_individual\")\n",
    "    ])\n",
    "\n",
    "    # Calculate cumulative gain for all possible sends\n",
    "    df_ordenado = df_ordenado.with_columns([\n",
    "        pl.col(\"ganancia_individual\").cum_sum().alias(\"ganancia_acumulada\")\n",
    "    ])\n",
    "\n",
    "    # Get the gain corresponding to the specified n_envios.\n",
    "    # If n_envios is larger than the dataframe, cap it at dataframe height.\n",
    "    # If n_envios is 0 or negative, return 0 gain and 0 sends.\n",
    "    if n_envios <= 0:\n",
    "        return 0.0, 0\n",
    "\n",
    "    # Ensure n_envios does not exceed the number of rows in the DataFrame\n",
    "    actual_n_envios = min(n_envios, df_ordenado.height)\n",
    "\n",
    "    if actual_n_envios == 0: # Case where df_ordenado is empty or n_envios <= 0\n",
    "        return 0.0, 0\n",
    "\n",
    "    # Get the cumulative gain at the actual_n_envios position (0-indexed: actual_n_envios - 1)\n",
    "    ganancia_at_n_envios = df_ordenado[\"ganancia_acumulada\"].item(actual_n_envios - 1)\n",
    "\n",
    "    return float(ganancia_at_n_envios), actual_n_envios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "OniyxM8OhY1o"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 23:31:57,891 - INFO - __main__ 21 - Performing client-based undersampling with fraction (proportion to KEEP): 0.5, DF shape: (4400034, 771)\n",
      "/tmp/ipykernel_5534/423577188.py:37: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  df_filtered = df.filter(\n",
      "2025-12-03 23:38:38,436 - INFO - __main__ 42 - DF shape after client-based undersampling: (2362446, 771)\n",
      "2025-12-03 23:39:39,547 - INFO - __main__ 19 - All predict models exist. Loading them.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve best n_envios from the study's best trial\n",
    "df_predict = df.filter(pl.col('foto_mes') == CONFIG[\"FINAL_PREDICT\"])\n",
    "df_train_predict = df.filter(pl.col('foto_mes').is_in(build_foto_mes(CONFIG[\"FINAL_TRAIN_FLOOR\"],CONFIG[\"FINAL_TRAIN_CEILING\"],CONFIG[\"MES_TO_DROP\"])))\n",
    "df_train_predict = undersample_df(df_train_predict, 0.5, CONFIG[\"IS_RANDOM_UNDERSAMPLING\"])\n",
    "df_train_predict = generate_clase_binaria(df_train_predict, is_prediction=True)\n",
    "\n",
    "predict_models = build_and_save_or_load_models(study, CONFIG[\"SEMILLA\"],df_train_predict, undersampling_fraction=CONFIG[\"UNDERSAMPLING_FRACTION\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EfkdNGr-pddC",
    "outputId": "1b1e86eb-cef4-4728-fcb8-a745c8fb65c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 00:10:53,015 - INFO - __main__ 16 - Build submission /home/tomas_freilij/buckets/b2/predictions.csv\n",
      "2025-12-04 00:11:30,235 - INFO - __main__ 20 - Program Ends\n"
     ]
    }
   ],
   "source": [
    "best_n_envios = 10500\n",
    "if CONFIG[\"IS_EXPERIMENTO\"]:\n",
    "\n",
    "  print(f\"Ganancia idealizada : { (df_predict.filter(pl.col('clase_ternaria') == 'BAJA+2').shape[0]) * CONFIG['GANANCIA_ACIERTO']}\")\n",
    "  comp_predictions = build_predictions(predict_models, df_predict, cols_train)\n",
    "  print(comp_predictions[\"Predicted\"].value_counts())\n",
    "\n",
    "  df_predict = generate_clase_binaria(df_predict,is_prediction = True)\n",
    "\n",
    "  _, ganancia, n_envios_final = calcular_cantidad_envios(comp_predictions, df_predict)\n",
    "  logger.info(f\"Ganancia en Prediccion de Experimento : {ganancia} con {n_envios_final} envios\")\n",
    "  print(f\"Ganancia en Prediccion de Experimento : {ganancia} con {n_envios_final} envios\")\n",
    "else:\n",
    "\n",
    "  prediction_path = Path(CONFIG[\"BUCKETS\"]) / CONFIG[\"BUCKET_TARGET\"] / \"predictions.csv\"\n",
    "  logger.info(f\"Build submission {prediction_path}\")\n",
    "  comp_predictions = build_final_predictions(predict_models, df_predict, best_n_envios, cols_train)\n",
    "  comp_predictions.write_csv(prediction_path)\n",
    "\n",
    "logger.info(f\"Program Ends\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rSgxoISo7FV",
    "outputId": "386c8b5b-9f52-45a3-a44c-a9439ff4eaf8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lgb.plot_importance(predict_models[50], figsize=(30, 40))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.filter(pl.col(\"foto_mes\") == 202108)[\"clase_ternaria\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
