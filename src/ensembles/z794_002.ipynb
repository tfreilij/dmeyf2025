{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cEmzeUKFkPh"
   },
   "source": [
    "# Tarea para el Hogar 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DenyKXkiJ5JN"
   },
   "source": [
    "##  1. Big Picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-K2_ZsZGrVD"
   },
   "source": [
    "LightGBM es el algoritmo estado del arte para datasets estructurados.\n",
    "<br> La Bayesian Optimization es el estado del arte para optimización de hiperparámetros\n",
    "<br> Las soluciones a las tres competencias de la asignatura contendrán LightGBMs y Bayesian Optimizations\n",
    "<br> LightGBM ha aumentado en forma no darwiniana sus hiperparámetros en los últimos ocho años; no todos los existentes son útiles.\n",
    "<br> Es necesario lograr entender cuales son los hiperparámetros relevantes de LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9GkTOk5J9t3"
   },
   "source": [
    "## 2. Hiperparámetros del LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmEFy0ukKL5T"
   },
   "source": [
    "Los objetivos de esta tarea son:\n",
    "\n",
    "\n",
    "*   Aumentar la rentabilidad de la campaña de marketing de retención proactiva de clientes.\n",
    "*   Generar un mejor modelo optimizando sus hiperparámetros\n",
    "*   Conceptual : investigar los mas relevantes hiperparámetros de LightGBM\n",
    "*   Familiarizarse con la Bayesian Optimization, sus largos tiempos de corrida y opciones para reducirlos\n",
    "*   Familiarizarse con el uso de máquinas virtuales de Google Colab\n",
    "*   Ver un pipeline completo de optimización de hiperparámetros y puesta en producción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yvlS6JQLRMd"
   },
   "source": [
    "LightGBM cuenta con mas de 60 hiperparámetros, siendo posible utilizar 40 al mismo tiempo, aunque no razonable.\n",
    "<br> La documentación oficial de los hiperparámetros de LightGBM es  https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eydI4YNAsFaf"
   },
   "source": [
    "Se lo alerta sobre que una Optimizacion Bayesiana lleva varias horas de corrida, y usted deberá correr VARIAS optimizaciones para descubrir cuales parámetros conviene optimizar.\n",
    "<br> A pesar que la próxima clase es recien en viernes 01 de agosto, inicie la tarea con tiempo, aprenda a planificar estratégicamente sus corridas como un@ científ@  de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzU4S0SeMcpp"
   },
   "source": [
    "Es necesario investigar cuales son los hiperparámetros de LightGBM que vale la pena optimizar en una Bayesian Optimization, ya que los realmente utiles son apenas un reducido subconjunto.\n",
    "<br>Usted deberá investigar cuales son los hiperparámetros mas relevantes de LightGBM, su primer alternativa es preguntándole a su amigo con capacidades especiales ChatGPT o sus endogámicos familiares Claude, DeepSeek, Gemini, Grok, etc\n",
    "<br> La segunda alternativa es la propia documentación de LightGBM  https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNptUgI_NWWG"
   },
   "source": [
    "Adicionalmente podra buscar información como la que proveen esta diminuta muestra aleatoria de artículos ligeros:\n",
    "*  https://medium.com/@sarahzouinina/a-deep-dive-into-lightgbm-how-to-choose-and-tune-parameters-7c584945842e\n",
    "*  https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
    "*  https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702/\n",
    "\n",
    "\n",
    "<br>  La muestra anterior se brinda a modo de ejemplo, usted deberá buscar muuuuchas  fuentes adicionales de información\n",
    "<br> Tenga presente que LightGBM es el estado del arte en modelado predictivo para datasets estructurado, que son el 90% del trabajo del 95% de los Data Scientists en Argentina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpUThBojODyK"
   },
   "source": [
    "El desafío de esta tarea es:\n",
    "* Qué hiperparparámetros conviene optimizar?  Las recomendaciones de los artículos ligeros es siempre sensata?  Sus autores realmente hicieron experimentos o son siemplemente escritores de entretenimiento carente de base científica?\n",
    "* Elegidos los hiperparámetros, cual es el  <desde, hasta> que se debe utilizar en la Bayesian Optimization ?\n",
    "* Realmente vale la pena optimizar 10 o 16 hiperparámetros al mismo tiempo ?  No resulta contraproducente una búsqueda en un espacio de tal alta dimensionalidad ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dseB4qb9RqUb"
   },
   "source": [
    "## Generacion de la clase_ternaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCEnE_02RuIQ"
   },
   "source": [
    "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Tipe -> Runtime type -> R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "P863YZB9R1Ua"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "\n"
     ]
    }
   ],
   "source": [
    "require( \"data.table\" )\n",
    "\n",
    "# leo el dataset\n",
    "dataset <- fread(\"/content/datasets/competencia_01_crudo.csv\" )\n",
    "\n",
    "# calculo el periodo0 consecutivo\n",
    "dsimple <- dataset[, list(\n",
    "    \"pos\" = .I,\n",
    "    numero_de_cliente,\n",
    "    periodo0 = as.integer(foto_mes/100)*12 +  foto_mes%%100 ) ]\n",
    "\n",
    "\n",
    "# ordeno\n",
    "setorder( dsimple, numero_de_cliente, periodo0 )\n",
    "\n",
    "# calculo topes\n",
    "periodo_ultimo <- dsimple[, max(periodo0) ]\n",
    "periodo_anteultimo <- periodo_ultimo - 1\n",
    "\n",
    "\n",
    "# calculo los leads de orden 1 y 2\n",
    "dsimple[, c(\"periodo1\", \"periodo2\") :=\n",
    "    shift(periodo0, n=1:2, fill=NA, type=\"lead\"),  numero_de_cliente ]\n",
    "\n",
    "# assign most common class values = \"CONTINUA\"\n",
    "dsimple[ periodo0 < periodo_anteultimo, clase_ternaria := \"CONTINUA\" ]\n",
    "\n",
    "# calculo BAJA+1\n",
    "dsimple[ periodo0 < periodo_ultimo &\n",
    "    ( is.na(periodo1) | periodo0 + 1 < periodo1 ),\n",
    "    clase_ternaria := \"BAJA+1\" ]\n",
    "\n",
    "# calculo BAJA+2\n",
    "dsimple[ periodo0 < periodo_anteultimo & (periodo0+1 == periodo1 )\n",
    "    & ( is.na(periodo2) | periodo0 + 2 < periodo2 ),\n",
    "    clase_ternaria := \"BAJA+2\" ]\n",
    "\n",
    "\n",
    "# pego el resultado en el dataset original y grabo\n",
    "setorder( dsimple, pos )\n",
    "dataset[, clase_ternaria := dsimple$clase_ternaria ]\n",
    "\n",
    "fwrite( dataset,\n",
    "    file =  \"/content/datasets/competencia_01.csv.gz\",\n",
    "    sep = \",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "S3hL7tv8W4rn"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 15 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>foto_mes</th><th scope=col>clase_ternaria</th><th scope=col>N</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>202101</td><td>BAJA+1  </td><td>   622</td></tr>\n",
       "\t<tr><td>202101</td><td>BAJA+2  </td><td>   825</td></tr>\n",
       "\t<tr><td>202101</td><td>CONTINUA</td><td>160080</td></tr>\n",
       "\t<tr><td>202102</td><td>BAJA+1  </td><td>   831</td></tr>\n",
       "\t<tr><td>202102</td><td>BAJA+2  </td><td>  1032</td></tr>\n",
       "\t<tr><td>202102</td><td>CONTINUA</td><td>160292</td></tr>\n",
       "\t<tr><td>202103</td><td>BAJA+1  </td><td>  1039</td></tr>\n",
       "\t<tr><td>202103</td><td>BAJA+2  </td><td>   951</td></tr>\n",
       "\t<tr><td>202103</td><td>CONTINUA</td><td>161119</td></tr>\n",
       "\t<tr><td>202104</td><td>BAJA+1  </td><td>   955</td></tr>\n",
       "\t<tr><td>202104</td><td>BAJA+2  </td><td>  1130</td></tr>\n",
       "\t<tr><td>202104</td><td>CONTINUA</td><td>161333</td></tr>\n",
       "\t<tr><td>202105</td><td>NA      </td><td>162783</td></tr>\n",
       "\t<tr><td>202105</td><td>BAJA+1  </td><td>  1134</td></tr>\n",
       "\t<tr><td>202106</td><td>NA      </td><td>164313</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 15 × 3\n",
       "\\begin{tabular}{lll}\n",
       " foto\\_mes & clase\\_ternaria & N\\\\\n",
       " <int> & <chr> & <int>\\\\\n",
       "\\hline\n",
       "\t 202101 & BAJA+1   &    622\\\\\n",
       "\t 202101 & BAJA+2   &    825\\\\\n",
       "\t 202101 & CONTINUA & 160080\\\\\n",
       "\t 202102 & BAJA+1   &    831\\\\\n",
       "\t 202102 & BAJA+2   &   1032\\\\\n",
       "\t 202102 & CONTINUA & 160292\\\\\n",
       "\t 202103 & BAJA+1   &   1039\\\\\n",
       "\t 202103 & BAJA+2   &    951\\\\\n",
       "\t 202103 & CONTINUA & 161119\\\\\n",
       "\t 202104 & BAJA+1   &    955\\\\\n",
       "\t 202104 & BAJA+2   &   1130\\\\\n",
       "\t 202104 & CONTINUA & 161333\\\\\n",
       "\t 202105 & NA       & 162783\\\\\n",
       "\t 202105 & BAJA+1   &   1134\\\\\n",
       "\t 202106 & NA       & 164313\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 15 × 3\n",
       "\n",
       "| foto_mes &lt;int&gt; | clase_ternaria &lt;chr&gt; | N &lt;int&gt; |\n",
       "|---|---|---|\n",
       "| 202101 | BAJA+1   |    622 |\n",
       "| 202101 | BAJA+2   |    825 |\n",
       "| 202101 | CONTINUA | 160080 |\n",
       "| 202102 | BAJA+1   |    831 |\n",
       "| 202102 | BAJA+2   |   1032 |\n",
       "| 202102 | CONTINUA | 160292 |\n",
       "| 202103 | BAJA+1   |   1039 |\n",
       "| 202103 | BAJA+2   |    951 |\n",
       "| 202103 | CONTINUA | 161119 |\n",
       "| 202104 | BAJA+1   |    955 |\n",
       "| 202104 | BAJA+2   |   1130 |\n",
       "| 202104 | CONTINUA | 161333 |\n",
       "| 202105 | NA       | 162783 |\n",
       "| 202105 | BAJA+1   |   1134 |\n",
       "| 202106 | NA       | 164313 |\n",
       "\n"
      ],
      "text/plain": [
       "   foto_mes clase_ternaria N     \n",
       "1  202101   BAJA+1            622\n",
       "2  202101   BAJA+2            825\n",
       "3  202101   CONTINUA       160080\n",
       "4  202102   BAJA+1            831\n",
       "5  202102   BAJA+2           1032\n",
       "6  202102   CONTINUA       160292\n",
       "7  202103   BAJA+1           1039\n",
       "8  202103   BAJA+2            951\n",
       "9  202103   CONTINUA       161119\n",
       "10 202104   BAJA+1            955\n",
       "11 202104   BAJA+2           1130\n",
       "12 202104   CONTINUA       161333\n",
       "13 202105   NA             162783\n",
       "14 202105   BAJA+1           1134\n",
       "15 202106   NA             164313"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setorder( dataset, foto_mes, clase_ternaria, numero_de_cliente)\n",
    "dataset[, .N, list(foto_mes, clase_ternaria)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSKhZRToy2F7"
   },
   "source": [
    "### 2.2 Optimizacion Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kwPpHAtSmix"
   },
   "source": [
    "Esta parte se debe correr con el runtime en lenguaje R Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp4-Bj3aYI8d"
   },
   "source": [
    "### 2.2.1 Inicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zy8YTZfESxeJ"
   },
   "source": [
    "limpio el ambiente de R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gBq__iAdQliq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Wed Oct 01 22:38:23 2025'"
      ],
      "text/latex": [
       "'Wed Oct 01 22:38:23 2025'"
      ],
      "text/markdown": [
       "'Wed Oct 01 22:38:23 2025'"
      ],
      "text/plain": [
       "[1] \"Wed Oct 01 22:38:23 2025\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7rdVrBojS1IV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 725929</td><td>38.8</td><td>  1454648</td><td>  77.7</td><td>  1454648</td><td>  77.7</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1422889</td><td>10.9</td><td>169514018</td><td>1293.3</td><td>211568082</td><td>1614.2</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  725929 & 38.8 &   1454648 &   77.7 &   1454648 &   77.7\\\\\n",
       "\tVcells & 1422889 & 10.9 & 169514018 & 1293.3 & 211568082 & 1614.2\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  725929 | 38.8 |   1454648 |   77.7 |   1454648 |   77.7 |\n",
       "| Vcells | 1422889 | 10.9 | 169514018 | 1293.3 | 211568082 | 1614.2 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb)   max used  (Mb)  \n",
       "Ncells  725929 38.8   1454648    77.7   1454648   77.7\n",
       "Vcells 1422889 10.9 169514018  1293.3 211568082 1614.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuPfQ7ksjwW3"
   },
   "source": [
    "### 2.2.2 Carga de Librerias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8BaSFlGfvma"
   },
   "source": [
    "Esta parte lleva varios minutos la primera vez en Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lVyxLaJ1j1J_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: parallel\n",
      "\n",
      "Loading required package: R.utils\n",
      "\n",
      "Loading required package: R.oo\n",
      "\n",
      "Loading required package: R.methodsS3\n",
      "\n",
      "R.methodsS3 v1.8.2 (2022-06-13 22:00:14 UTC) successfully loaded. See ?R.methodsS3 for help.\n",
      "\n",
      "R.oo v1.27.1 (2025-05-02 21:00:05 UTC) successfully loaded. See ?R.oo for help.\n",
      "\n",
      "\n",
      "Attaching package: ‘R.oo’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:R.methodsS3’:\n",
      "\n",
      "    throw\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:methods’:\n",
      "\n",
      "    getClasses, getMethods\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    attach, detach, load, save\n",
      "\n",
      "\n",
      "R.utils v2.13.0 (2025-02-24 21:20:02 UTC) successfully loaded. See ?R.utils for help.\n",
      "\n",
      "\n",
      "Attaching package: ‘R.utils’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:utils’:\n",
      "\n",
      "    timestamp\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    cat, commandArgs, getOption, isOpen, nullfile, parse, use, warnings\n",
      "\n",
      "\n",
      "Loading required package: primes\n",
      "\n",
      "Loading required package: rlist\n",
      "\n",
      "Loading required package: yaml\n",
      "\n",
      "Loading required package: lightgbm\n",
      "\n",
      "Loading required package: DiceKriging\n",
      "\n",
      "Loading required package: mlrMBO\n",
      "\n",
      "Loading required package: mlr\n",
      "\n",
      "Loading required package: ParamHelpers\n",
      "\n",
      "\n",
      "Attaching package: ‘ParamHelpers’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:R.utils’:\n",
      "\n",
      "    isVector\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘mlr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:R.utils’:\n",
      "\n",
      "    resample, setThreshold\n",
      "\n",
      "\n",
      "Loading required package: smoof\n",
      "\n",
      "Loading required package: checkmate\n",
      "\n",
      "\n",
      "Attaching package: ‘checkmate’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:DiceKriging’:\n",
      "\n",
      "    checkNames\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:R.utils’:\n",
      "\n",
      "    asInt\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘smoof’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:R.oo’:\n",
      "\n",
      "    getDescription, getName\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cargo las librerias que necesito\n",
    "require(\"data.table\")\n",
    "require(\"parallel\")\n",
    "\n",
    "if(!require(\"R.utils\")) install.packages(\"R.utils\")\n",
    "require(\"R.utils\")\n",
    "\n",
    "if( !require(\"primes\") ) install.packages(\"primes\")\n",
    "require(\"primes\")\n",
    "\n",
    "if( !require(\"utils\") ) install.packages(\"utils\")\n",
    "require(\"utils\")\n",
    "\n",
    "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
    "require(\"rlist\")\n",
    "\n",
    "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
    "require(\"yaml\")\n",
    "\n",
    "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")\n",
    "\n",
    "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
    "require(\"DiceKriging\")\n",
    "\n",
    "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
    "require(\"mlrMBO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iz-6Qt6BUaA3"
   },
   "source": [
    "### 2.2.3 Definicion de Parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOdlKd7lUm2I"
   },
   "source": [
    "aqui debe cargar SU semilla primigenia\n",
    "<br>recuerde cambiar el numero de experimento en cada corrida nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ASYkebOu2mF6"
   },
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$experimento <- \"794_002\"\n",
    "PARAM$semilla_primigenia <- 102191\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ezOhQdbA293o"
   },
   "outputs": [],
   "source": [
    "# training y future\n",
    "PARAM$train <- c(202101, 202102, 202103, 202104)\n",
    "PARAM$train_final <- c(202101, 202102, 202103, 202104)\n",
    "PARAM$future <- c(202106)\n",
    "PARAM$semilla_kaggle <- 314159\n",
    "PARAM$cortes <- seq(9000, 13000, by= 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jtB0Lub42rHO"
   },
   "outputs": [],
   "source": [
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "# undersampling de 1.0  implica tomar TODOS los datos\n",
    "\n",
    "PARAM$trainingstrategy$undersampling <- 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OFxm-xiNUOJX"
   },
   "outputs": [],
   "source": [
    "# Parametros LightGBM\n",
    "\n",
    "PARAM$hyperparametertuning$xval_folds <- 5\n",
    "\n",
    "# parametros fijos del LightGBM que se pisaran con la parte variable de la BO\n",
    "PARAM$lgbm$param_fijos <-  list(\n",
    "  boosting= \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
    "  objective= \"binary\",\n",
    "  metric= \"auc\",\n",
    "  first_metric_only= FALSE,\n",
    "  boost_from_average= TRUE,\n",
    "  feature_pre_filter= FALSE,\n",
    "  force_row_wise= TRUE, # para reducir warnings\n",
    "  verbosity= -100,\n",
    "\n",
    "  seed= PARAM$semilla_primigenia,\n",
    "\n",
    "  max_depth= -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split= 0, # min_gain_to_split >= 0\n",
    "  min_sum_hessian_in_leaf= 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1= 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2= 0.0, # lambda_l2 >= 0.0\n",
    "  max_bin= 31L, # lo debo dejar fijo, no participa de la BO\n",
    "\n",
    "  bagging_fraction= 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction= 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction= 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance= FALSE, #\n",
    "  scale_pos_weight= 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate= 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop= 50, # <=0 means no limit\n",
    "  skip_drop= 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees= FALSE,\n",
    "\n",
    "  num_iterations= 1200,\n",
    "  learning_rate= 0.02,\n",
    "  feature_fraction= 0.5,\n",
    "  num_leaves= 750,\n",
    "  min_data_in_leaf= 5000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5Yj-JV4yvOt"
   },
   "source": [
    "Aqui se definen los hiperparámetros de LightGBM que participan de la Bayesian Optimization\n",
    "<br> si es un numero entero debe ir  makeIntegerParam\n",
    "<br> si es un numero real (con decimales) debe ir  makeNumericParam\n",
    "<br> es muy importante leer cuales son un lower y upper  permitidos y ademas razonables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jENpR26ZyuS8"
   },
   "outputs": [],
   "source": [
    "# Aqui se cargan los bordes de los hiperparametros de la BO\n",
    "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
    "  makeIntegerParam(\"num_iterations\", lower= 8L, upper= 2048L),\n",
    "  makeNumericParam(\"learning_rate\", lower= 0.01, upper= 0.3),\n",
    "  makeNumericParam(\"feature_fraction\", lower= 0.1, upper= 1.0),\n",
    "  makeIntegerParam(\"num_leaves\", lower= 8L, upper= 2048L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower= 1L, upper= 8000L)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_RPFUb3zMoW"
   },
   "source": [
    "A mayor cantidad de hiperparámetros, se debe aumentar las iteraciones de la Bayesian Optimization\n",
    "<br> 30 es un valor muy tacaño, pero corre rápido\n",
    "<br> deberia partir de 50, alcanzando los 100 si se dispone de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "q5Rd3pnbzSiG"
   },
   "outputs": [],
   "source": [
    "PARAM$hyperparametertuning$iteraciones <- 30 # iteraciones bayesianas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "or53-q3bmE5d"
   },
   "outputs": [],
   "source": [
    "# particionar agrega una columna llamada fold a un dataset\n",
    "#   que consiste en una particion estratificada segun agrupa\n",
    "# particionar( data=dataset, division=c(70,30),\n",
    "#  agrupa=clase_ternaria, seed=semilla)   crea una particion 70, 30\n",
    "\n",
    "particionar <- function(data, division, agrupa= \"\", campo= \"fold\", start= 1, seed= NA) {\n",
    "  if (!is.na(seed)) set.seed(seed, \"L'Ecuyer-CMRG\")\n",
    "\n",
    "  bloque <- unlist(mapply(\n",
    "    function(x, y) {rep(y, x)},division, seq(from= start, length.out= length(division))))\n",
    "\n",
    "  data[, (campo) := sample(rep(bloque,ceiling(.N / length(bloque))))[1:.N],by= agrupa]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CGKOZ9aMmKxi"
   },
   "outputs": [],
   "source": [
    "# iniciliazo el dataset de realidad, para medir ganancia\n",
    "realidad_inicializar <- function( pfuture, pparam) {\n",
    "\n",
    "  # datos para verificar la ganancia\n",
    "  drealidad <- pfuture[, list(numero_de_cliente, foto_mes, clase_ternaria)]\n",
    "\n",
    "  particionar(drealidad,\n",
    "    division= c(3, 7),\n",
    "    agrupa= \"clase_ternaria\",\n",
    "    seed= PARAM$semilla_kaggle\n",
    "  )\n",
    "\n",
    "  return( drealidad )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6aVLFlEbmM3s"
   },
   "outputs": [],
   "source": [
    "# evaluo ganancia en los datos de la realidad\n",
    "\n",
    "realidad_evaluar <- function( prealidad, pprediccion) {\n",
    "\n",
    "  prealidad[ pprediccion,\n",
    "    on= c(\"numero_de_cliente\", \"foto_mes\"),\n",
    "    predicted:= i.Predicted\n",
    "  ]\n",
    "\n",
    "  tbl <- prealidad[, list(\"qty\"=.N), list(fold, predicted, clase_ternaria)]\n",
    "\n",
    "  res <- list()\n",
    "  res$public  <- tbl[fold==1 & predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]/0.3\n",
    "  res$private <- tbl[fold==2 & predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]/0.7\n",
    "  res$total <- tbl[predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]\n",
    "\n",
    "  prealidad[, predicted:=NULL]\n",
    "  return( res )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RWZXL1VZjMI"
   },
   "source": [
    "### 2.2.4  Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "j3toG9-lZm4K"
   },
   "outputs": [],
   "source": [
    "# carpeta de trabajo\n",
    "\n",
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento_folder <- paste0(\"HT\", PARAM$experimento)\n",
    "dir.create(experimento_folder, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FM3lxKoLZ643"
   },
   "outputs": [],
   "source": [
    "# lectura del dataset\n",
    "dataset <- fread(\"/content/datasets/competencia_01.csv.gz\", stringsAsFactors= TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion de LAGs\n",
    "setorder(dataset, numero_de_cliente, foto_mes)\n",
    "\n",
    "# todo es lagueable, menos la primary key y la clase\n",
    "cols_lagueables <- copy( setdiff(\n",
    "    colnames(dataset),\n",
    "    c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\")\n",
    ") )\n",
    "\n",
    "# https://rdrr.io/cran/data.table/man/shift.html\n",
    "\n",
    "# lags de orden 1\n",
    "dataset[,\n",
    "    paste0(cols_lagueables, \"_lag1\") := shift(.SD, 1, NA, \"lag\"),\n",
    "    by = numero_de_cliente,\n",
    "    .SDcols = cols_lagueables\n",
    "]\n",
    "\n",
    "# lags de orden 2\n",
    "dataset[,\n",
    "    paste0(cols_lagueables, \"_lag2\") := shift(.SD, 2, NA, \"lag\"),\n",
    "    by = numero_de_cliente,\n",
    "    .SDcols = cols_lagueables\n",
    "]\n",
    "\n",
    "# agrego los delta lags\n",
    "for (vcol in cols_lagueables)\n",
    "{\n",
    "    dataset[, paste0(vcol, \"_delta1\") := get(vcol) - get(paste0(vcol, \"_lag1\"))]\n",
    "    dataset[, paste0(vcol, \"_delta2\") := get(vcol) - get(paste0(vcol, \"_lag2\"))]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "OsJ-91UeZ-I_"
   },
   "outputs": [],
   "source": [
    "dataset_train <- dataset[foto_mes %in% PARAM$train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vrWE7BE0aB2J"
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "#  a partir de ahora ya NO puedo cortar  por prob(BAJA+2) > 1/40\n",
    "\n",
    "dataset_train[,\n",
    "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jP7YlQBnaW6W"
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "# notar que para esto utilizo la SEGUNDA semilla\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset_train[, azar := runif(nrow(dataset_train))]\n",
    "dataset_train[, training := 0L]\n",
    "\n",
    "dataset_train[\n",
    "  foto_mes %in%  PARAM$train &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xElu4s5W4rX7"
   },
   "outputs": [],
   "source": [
    "# los campos que se van a utilizar\n",
    "\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset_train),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "PppMHcGYaaol"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "328393"
      ],
      "text/latex": [
       "328393"
      ],
      "text/markdown": [
       "328393"
      ],
      "text/plain": [
       "[1] 328393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "762"
      ],
      "text/latex": [
       "762"
      ],
      "text/markdown": [
       "762"
      ],
      "text/plain": [
       "[1] 762"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "nrow(dtrain)\n",
    "ncol(dtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ta-EkOu3cphF"
   },
   "source": [
    "2.2.5 Configuracion Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "cjgfurjdfiXb"
   },
   "outputs": [],
   "source": [
    "# En el argumento x llegan los parmaetros de la bayesiana\n",
    "#  devuelve la AUC en cross validation del modelo entrenado\n",
    "\n",
    "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
    "\n",
    "  # x pisa (o agrega) a param_fijos\n",
    "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
    "\n",
    "  # entreno LightGBM\n",
    "  modelocv <- lgb.cv(\n",
    "    data= dtrain,\n",
    "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
    "    stratified= TRUE,\n",
    "    param= param_completo\n",
    "  )\n",
    "\n",
    "  # obtengo la ganancia\n",
    "  AUC <- modelocv$best_score\n",
    "\n",
    "  # hago espacio en la memoria\n",
    "  rm(modelocv)\n",
    "  gc(full= TRUE, verbose= FALSE)\n",
    "\n",
    "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
    "\n",
    "  return(AUC)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WLi_o1hocvN-"
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "\n",
    "# en este archivo quedan la evolucion binaria de la BO\n",
    "kbayesiana <- \"bayesiana.RDATA\"\n",
    "\n",
    "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output= FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize= FALSE, # estoy Maximizando la ganancia\n",
    "  noisy= TRUE,\n",
    "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
    "  has.simple.signature= FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
    "  save.file.path= kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters= PARAM$hyperparametertuning$iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type= \"se\",\n",
    "  covtype= \"matern3_2\",\n",
    "  control= list(trace= TRUE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uUeVo5pc4zc"
   },
   "source": [
    "2.2.6 Corrida Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "RcABNaKGciaz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing y column(s) for design. Not provided.\n",
      "\n",
      "Wed Oct 01 22:52:02 2025 AUC 0.937252192512018\n",
      "\n",
      "Wed Oct 01 23:10:12 2025 AUC 0.935559364474851\n",
      "\n",
      "Wed Oct 01 23:20:15 2025 AUC 0.934795410240402\n",
      "\n",
      "Wed Oct 01 23:25:52 2025 AUC 0.935394504376019\n",
      "\n",
      "Wed Oct 01 23:42:43 2025 AUC 0.936906928033191\n",
      "\n",
      "Thu Oct 02 00:06:44 2025 AUC 0.938535802922521\n",
      "\n",
      "Thu Oct 02 00:12:29 2025 AUC 0.933088948200435\n",
      "\n",
      "Thu Oct 02 00:27:42 2025 AUC 0.942181716247337\n",
      "\n",
      "Thu Oct 02 00:47:27 2025 AUC 0.9334930099763\n",
      "\n",
      "Thu Oct 02 01:15:27 2025 AUC 0.936051306252049\n",
      "\n",
      "Thu Oct 02 01:16:24 2025 AUC 0.930920558383013\n",
      "\n",
      "Thu Oct 02 01:21:32 2025 AUC 0.935070306668391\n",
      "\n",
      "Thu Oct 02 01:38:29 2025 AUC 0.931929672224428\n",
      "\n",
      "Thu Oct 02 02:00:11 2025 AUC 0.940754496769988\n",
      "\n",
      "Thu Oct 02 02:03:38 2025 AUC 0.937207638613677\n",
      "\n",
      "Thu Oct 02 02:16:35 2025 AUC 0.933622149302138\n",
      "\n",
      "Thu Oct 02 02:34:18 2025 AUC 0.937600052623608\n",
      "\n",
      "Thu Oct 02 02:39:31 2025 AUC 0.936680169860638\n",
      "\n",
      "Thu Oct 02 02:42:39 2025 AUC 0.929967805363634\n",
      "\n",
      "Thu Oct 02 03:00:19 2025 AUC 0.936931204865026\n",
      "\n",
      "[mbo] 0: num_iterations=1007; learning_rate=0.187; feature_fraction=0.8; num_leaves=1372; min_data_in_leaf=3828 : y = 0.937 : 721.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1169; learning_rate=0.116; feature_fraction=0.466; num_leaves=1089; min_data_in_leaf=4294 : y = 0.936 : 1090.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=813; learning_rate=0.141; feature_fraction=0.6; num_leaves=243; min_data_in_leaf=6848 : y = 0.935 : 602.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=438; learning_rate=0.268; feature_fraction=0.904; num_leaves=919; min_data_in_leaf=1966 : y = 0.935 : 337.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1118; learning_rate=0.127; feature_fraction=0.411; num_leaves=1005; min_data_in_leaf=3224 : y = 0.937 : 1010.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1836; learning_rate=0.161; feature_fraction=0.744; num_leaves=1709; min_data_in_leaf=1252 : y = 0.939 : 1441.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=629; learning_rate=0.222; feature_fraction=0.992; num_leaves=332; min_data_in_leaf=6122 : y = 0.933 : 345.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=838; learning_rate=0.0718; feature_fraction=0.927; num_leaves=1291; min_data_in_leaf=811 : y = 0.942 : 912.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1464; learning_rate=0.239; feature_fraction=0.27; num_leaves=1924; min_data_in_leaf=268 : y = 0.933 : 1185.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1690; learning_rate=0.0978; feature_fraction=0.562; num_leaves=1804; min_data_in_leaf=5328 : y = 0.936 : 1680.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=50; learning_rate=0.21; feature_fraction=0.511; num_leaves=1173; min_data_in_leaf=5720 : y = 0.931 : 56.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=413; learning_rate=0.05; feature_fraction=0.307; num_leaves=419; min_data_in_leaf=7819 : y = 0.935 : 308.8 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1314; learning_rate=0.251; feature_fraction=0.333; num_leaves=523; min_data_in_leaf=6491 : y = 0.932 : 1016.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1855; learning_rate=0.0212; feature_fraction=0.22; num_leaves=1467; min_data_in_leaf=2294 : y = 0.941 : 1302.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=150; learning_rate=0.0944; feature_fraction=0.442; num_leaves=758; min_data_in_leaf=491 : y = 0.937 : 206.8 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1344; learning_rate=0.282; feature_fraction=0.653; num_leaves=1572; min_data_in_leaf=5050 : y = 0.934 : 777.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1592; learning_rate=0.171; feature_fraction=0.836; num_leaves=80; min_data_in_leaf=2859 : y = 0.938 : 1062.4 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=535; learning_rate=0.0641; feature_fraction=0.698; num_leaves=1988; min_data_in_leaf=4664 : y = 0.937 : 313.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=285; learning_rate=0.288; feature_fraction=0.179; num_leaves=668; min_data_in_leaf=2438 : y = 0.93 : 188.4 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1980; learning_rate=0.0341; feature_fraction=0.143; num_leaves=122; min_data_in_leaf=7332 : y = 0.937 : 1059.7 secs : initdesign\n",
      "\n",
      "Saved the current state after iteration 1 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 03:15:45 2025 AUC 0.938415209742486\n",
      "\n",
      "[mbo] 1: num_iterations=1151; learning_rate=0.0101; feature_fraction=1; num_leaves=1432; min_data_in_leaf=1681 : y = 0.938 : 923.3 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 2 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 03:32:26 2025 AUC 0.942367423124121\n",
      "\n",
      "[mbo] 2: num_iterations=904; learning_rate=0.0933; feature_fraction=0.894; num_leaves=1249; min_data_in_leaf=2 : y = 0.942 : 999.0 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 3 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 03:49:53 2025 AUC 0.94451807220936\n",
      "\n",
      "[mbo] 3: num_iterations=825; learning_rate=0.0718; feature_fraction=0.867; num_leaves=687; min_data_in_leaf=14 : y = 0.945 : 1043.9 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 4 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 03:57:42 2025 AUC 0.939120800692167\n",
      "\n",
      "[mbo] 4: num_iterations=796; learning_rate=0.0188; feature_fraction=0.828; num_leaves=113; min_data_in_leaf=1 : y = 0.939 : 466.8 secs : infill_ei\n",
      "\n",
      "Thu Oct 02 04:19:04 2025 AUC 0.946233014946333\n",
      "\n",
      "[mbo] 5: num_iterations=1261; learning_rate=0.0737; feature_fraction=0.856; num_leaves=459; min_data_in_leaf=5 : y = 0.946 : 1282.0 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 6 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 04:46:39 2025 AUC 0.943939858667511\n",
      "\n",
      "[mbo] 6: num_iterations=1904; learning_rate=0.0752; feature_fraction=0.886; num_leaves=467; min_data_in_leaf=2 : y = 0.944 : 1652.1 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 7 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 04:54:28 2025 AUC 0.935746677755131\n",
      "\n",
      "[mbo] 7: num_iterations=1244; learning_rate=0.0774; feature_fraction=0.856; num_leaves=46; min_data_in_leaf=42 : y = 0.936 : 467.2 secs : infill_ei\n",
      "\n",
      "Thu Oct 02 05:18:46 2025 AUC 0.94620039781626\n",
      "\n",
      "[mbo] 8: num_iterations=1032; learning_rate=0.0506; feature_fraction=0.832; num_leaves=503; min_data_in_leaf=207 : y = 0.946 : 1456.4 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 9 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 05:36:19 2025 AUC 0.944621048747945\n",
      "\n",
      "[mbo] 9: num_iterations=806; learning_rate=0.0818; feature_fraction=0.821; num_leaves=481; min_data_in_leaf=177 : y = 0.945 : 1050.6 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 10 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 06:05:14 2025 AUC 0.946338642790955\n",
      "\n",
      "[mbo] 10: num_iterations=1304; learning_rate=0.0254; feature_fraction=0.962; num_leaves=516; min_data_in_leaf=1 : y = 0.946 : 1733.4 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 11 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 06:28:46 2025 AUC 0.945376543676434\n",
      "\n",
      "[mbo] 11: num_iterations=1272; learning_rate=0.061; feature_fraction=0.783; num_leaves=569; min_data_in_leaf=8 : y = 0.945 : 1409.3 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 12 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 06:52:06 2025 AUC 0.945671503326204\n",
      "\n",
      "[mbo] 12: num_iterations=1145; learning_rate=0.0411; feature_fraction=0.945; num_leaves=459; min_data_in_leaf=46 : y = 0.946 : 1397.9 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 13 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 07:20:40 2025 AUC 0.945841862944507\n",
      "\n",
      "[mbo] 13: num_iterations=1290; learning_rate=0.011; feature_fraction=0.859; num_leaves=517; min_data_in_leaf=5 : y = 0.946 : 1711.7 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 14 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 07:44:23 2025 AUC 0.944877988705482\n",
      "\n",
      "[mbo] 14: num_iterations=1451; learning_rate=0.0738; feature_fraction=0.978; num_leaves=484; min_data_in_leaf=13 : y = 0.945 : 1420.4 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 15 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 08:11:25 2025 AUC 0.945770733007794\n",
      "\n",
      "[mbo] 15: num_iterations=1290; learning_rate=0.0527; feature_fraction=0.878; num_leaves=523; min_data_in_leaf=95 : y = 0.946 : 1619.4 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 16 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 08:24:35 2025 AUC 0.93383768990884\n",
      "\n",
      "[mbo] 16: num_iterations=990; learning_rate=0.174; feature_fraction=0.782; num_leaves=492; min_data_in_leaf=2 : y = 0.934 : 786.9 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 17 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 08:41:15 2025 AUC 0.940537902715155\n",
      "\n",
      "[mbo] 17: num_iterations=1087; learning_rate=0.0266; feature_fraction=0.832; num_leaves=491; min_data_in_leaf=1151 : y = 0.941 : 997.7 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 18 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 09:01:37 2025 AUC 0.94565989014594\n",
      "\n",
      "[mbo] 18: num_iterations=927; learning_rate=0.028; feature_fraction=0.838; num_leaves=516; min_data_in_leaf=1 : y = 0.946 : 1220.0 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 19 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 09:17:02 2025 AUC 0.944157797917004\n",
      "\n",
      "[mbo] 19: num_iterations=602; learning_rate=0.0134; feature_fraction=0.999; num_leaves=605; min_data_in_leaf=7 : y = 0.944 : 922.5 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 20 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 09:36:56 2025 AUC 0.944095686806846\n",
      "\n",
      "[mbo] 20: num_iterations=1074; learning_rate=0.0675; feature_fraction=0.723; num_leaves=476; min_data_in_leaf=1 : y = 0.944 : 1191.3 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 21 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 10:09:22 2025 AUC 0.946117712217104\n",
      "\n",
      "[mbo] 21: num_iterations=1248; learning_rate=0.0221; feature_fraction=0.966; num_leaves=674; min_data_in_leaf=12 : y = 0.946 : 1943.3 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 22 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 10:55:19 2025 AUC 0.946341450208983\n",
      "\n",
      "[mbo] 22: num_iterations=1373; learning_rate=0.0105; feature_fraction=0.956; num_leaves=924; min_data_in_leaf=2 : y = 0.946 : 2754.2 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 23 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 11:35:43 2025 AUC 0.946258754668963\n",
      "\n",
      "[mbo] 23: num_iterations=1626; learning_rate=0.0287; feature_fraction=0.974; num_leaves=847; min_data_in_leaf=1 : y = 0.946 : 2422.1 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 24 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 12:02:49 2025 AUC 0.944421924488864\n",
      "\n",
      "[mbo] 24: num_iterations=1550; learning_rate=0.0648; feature_fraction=0.837; num_leaves=2037; min_data_in_leaf=4 : y = 0.944 : 1623.6 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 25 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 12:47:00 2025 AUC 0.943993453596389\n",
      "\n",
      "[mbo] 25: num_iterations=1381; learning_rate=0.0189; feature_fraction=0.96; num_leaves=845; min_data_in_leaf=267 : y = 0.944 : 2648.0 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 26 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 13:44:39 2025 AUC 0.945803205332083\n",
      "\n",
      "[mbo] 26: num_iterations=1675; learning_rate=0.0102; feature_fraction=0.988; num_leaves=989; min_data_in_leaf=9 : y = 0.946 : 3457.2 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 27 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 14:14:09 2025 AUC 0.945235090543456\n",
      "\n",
      "[mbo] 27: num_iterations=1370; learning_rate=0.0457; feature_fraction=0.85; num_leaves=1002; min_data_in_leaf=1 : y = 0.945 : 1766.7 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 28 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 14:44:02 2025 AUC 0.945182640936597\n",
      "\n",
      "[mbo] 28: num_iterations=1477; learning_rate=0.0495; feature_fraction=0.873; num_leaves=1636; min_data_in_leaf=2 : y = 0.945 : 1791.0 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 29 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 15:33:52 2025 AUC 0.946717539923489\n",
      "\n",
      "[mbo] 29: num_iterations=1895; learning_rate=0.0102; feature_fraction=0.977; num_leaves=641; min_data_in_leaf=3 : y = 0.947 : 2987.0 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 30 in the file bayesiana.RDATA.\n",
      "\n",
      "Thu Oct 02 15:58:31 2025 AUC 0.942658300483872\n",
      "\n",
      "[mbo] 30: num_iterations=1264; learning_rate=0.065; feature_fraction=0.97; num_leaves=1832; min_data_in_leaf=1 : y = 0.943 : 1477.0 secs : infill_ei\n",
      "\n",
      "Saved the final state in the file bayesiana.RDATA\n",
      "\n",
      "Saved the final state in the file bayesiana.RDATA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inicio la optimizacion bayesiana, retomando si ya existe\n",
    "# es la celda mas lenta de todo el notebook\n",
    "\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "} else {\n",
    "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ssk5nnMk6INK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'num_iterations'</li><li>'learning_rate'</li><li>'feature_fraction'</li><li>'num_leaves'</li><li>'min_data_in_leaf'</li><li>'y'</li><li>'dob'</li><li>'eol'</li><li>'error.message'</li><li>'exec.time'</li><li>'ei'</li><li>'error.model'</li><li>'train.time'</li><li>'prop.type'</li><li>'propose.time'</li><li>'se'</li><li>'mean'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'num\\_iterations'\n",
       "\\item 'learning\\_rate'\n",
       "\\item 'feature\\_fraction'\n",
       "\\item 'num\\_leaves'\n",
       "\\item 'min\\_data\\_in\\_leaf'\n",
       "\\item 'y'\n",
       "\\item 'dob'\n",
       "\\item 'eol'\n",
       "\\item 'error.message'\n",
       "\\item 'exec.time'\n",
       "\\item 'ei'\n",
       "\\item 'error.model'\n",
       "\\item 'train.time'\n",
       "\\item 'prop.type'\n",
       "\\item 'propose.time'\n",
       "\\item 'se'\n",
       "\\item 'mean'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'num_iterations'\n",
       "2. 'learning_rate'\n",
       "3. 'feature_fraction'\n",
       "4. 'num_leaves'\n",
       "5. 'min_data_in_leaf'\n",
       "6. 'y'\n",
       "7. 'dob'\n",
       "8. 'eol'\n",
       "9. 'error.message'\n",
       "10. 'exec.time'\n",
       "11. 'ei'\n",
       "12. 'error.model'\n",
       "13. 'train.time'\n",
       "14. 'prop.type'\n",
       "15. 'propose.time'\n",
       "16. 'se'\n",
       "17. 'mean'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"num_iterations\"   \"learning_rate\"    \"feature_fraction\" \"num_leaves\"      \n",
       " [5] \"min_data_in_leaf\" \"y\"                \"dob\"              \"eol\"             \n",
       " [9] \"error.message\"    \"exec.time\"        \"ei\"               \"error.model\"     \n",
       "[13] \"train.time\"       \"prop.type\"        \"propose.time\"     \"se\"              \n",
       "[17] \"mean\"            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "colnames( tb_bayesiana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "u4zq-vknhjGc"
   },
   "outputs": [],
   "source": [
    "# almaceno los resultados de la Bayesian Optimization\n",
    "# y capturo los mejores hiperparametros encontrados\n",
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "\n",
    "tb_bayesiana[, iter := .I]\n",
    "\n",
    "# ordeno en forma descendente por AUC = y\n",
    "setorder(tb_bayesiana, -y)\n",
    "\n",
    "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
    "fwrite( tb_bayesiana,\n",
    "  file= \"BO_log.txt\",\n",
    "  sep= \"\\t\"\n",
    ")\n",
    "\n",
    "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
    "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
    "  1, # el primero es el de mejor AUC\n",
    "  setdiff(colnames(tb_bayesiana),\n",
    "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
    "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
    "  with= FALSE\n",
    "]\n",
    "\n",
    "\n",
    "PARAM$out$lgbm$y <- tb_bayesiana[1, y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "E8v2eA427N8e"
   },
   "outputs": [],
   "source": [
    "write_yaml( PARAM, file=\"PARAM.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "iBTWexVU7PGC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_iterations learning_rate feature_fraction num_leaves min_data_in_leaf\n",
      "            <int>         <num>            <num>      <int>            <int>\n",
      "1:           1895    0.01022218        0.9771859        641                3\n",
      "[1] 0.9467175\n"
     ]
    }
   ],
   "source": [
    "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
    "print(PARAM$out$lgbm$y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKsVZmAnhwX-"
   },
   "source": [
    "## 2.3  Produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ_C33Tr5B_9"
   },
   "source": [
    "### Final Training\n",
    "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "eDqfyA14hzwv"
   },
   "outputs": [],
   "source": [
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento <- paste0(\"exp\", PARAM$experimento)\n",
    "dir.create(experimento, showWarnings= FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qFmFivf5Iet"
   },
   "source": [
    "#### Final Training Dataset\n",
    "\n",
    "Aqui esta la gran decision de en qué meses hago el Final Training\n",
    "<br> debo utilizar los mejores hiperparámetros que encontré en la  optimización bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "lg5WVZncvc7H"
   },
   "outputs": [],
   "source": [
    "# clase01\n",
    "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "yc9QzXREv0xf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 3 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>clase_ternaria</th><th scope=col>N</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>CONTINUA</td><td>642824</td></tr>\n",
       "\t<tr><td>BAJA+2  </td><td>  3938</td></tr>\n",
       "\t<tr><td>BAJA+1  </td><td>  3447</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 3 × 2\n",
       "\\begin{tabular}{ll}\n",
       " clase\\_ternaria & N\\\\\n",
       " <fct> & <int>\\\\\n",
       "\\hline\n",
       "\t CONTINUA & 642824\\\\\n",
       "\t BAJA+2   &   3938\\\\\n",
       "\t BAJA+1   &   3447\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 3 × 2\n",
       "\n",
       "| clase_ternaria &lt;fct&gt; | N &lt;int&gt; |\n",
       "|---|---|\n",
       "| CONTINUA | 642824 |\n",
       "| BAJA+2   |   3938 |\n",
       "| BAJA+1   |   3447 |\n",
       "\n"
      ],
      "text/plain": [
       "  clase_ternaria N     \n",
       "1 CONTINUA       642824\n",
       "2 BAJA+2           3938\n",
       "3 BAJA+1           3447"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_train <- dataset[foto_mes %in% PARAM$train_final]\n",
    "dataset_train[,.N,clase_ternaria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "thjdqEBLuvNt"
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain_final <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train[, clase01]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNUa-WSz5Oqu"
   },
   "source": [
    "#### Final Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "FgCcvBfEwImu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$boosting</dt>\n",
       "\t\t<dd>'gbdt'</dd>\n",
       "\t<dt>$objective</dt>\n",
       "\t\t<dd>'binary'</dd>\n",
       "\t<dt>$metric</dt>\n",
       "\t\t<dd>'auc'</dd>\n",
       "\t<dt>$first_metric_only</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$boost_from_average</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$feature_pre_filter</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$force_row_wise</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$verbosity</dt>\n",
       "\t\t<dd>-100</dd>\n",
       "\t<dt>$seed</dt>\n",
       "\t\t<dd>102191</dd>\n",
       "\t<dt>$max_depth</dt>\n",
       "\t\t<dd>-1</dd>\n",
       "\t<dt>$min_gain_to_split</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>$min_sum_hessian_in_leaf</dt>\n",
       "\t\t<dd>0.001</dd>\n",
       "\t<dt>$lambda_l1</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>$lambda_l2</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>$max_bin</dt>\n",
       "\t\t<dd>31</dd>\n",
       "\t<dt>$bagging_fraction</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$pos_bagging_fraction</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$neg_bagging_fraction</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$is_unbalance</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$scale_pos_weight</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$drop_rate</dt>\n",
       "\t\t<dd>0.1</dd>\n",
       "\t<dt>$max_drop</dt>\n",
       "\t\t<dd>50</dd>\n",
       "\t<dt>$skip_drop</dt>\n",
       "\t\t<dd>0.5</dd>\n",
       "\t<dt>$extra_trees</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$num_iterations</dt>\n",
       "\t\t<dd>1895</dd>\n",
       "\t<dt>$learning_rate</dt>\n",
       "\t\t<dd>0.0102221811029723</dd>\n",
       "\t<dt>$feature_fraction</dt>\n",
       "\t\t<dd>0.977185861262148</dd>\n",
       "\t<dt>$num_leaves</dt>\n",
       "\t\t<dd>641</dd>\n",
       "\t<dt>$min_data_in_leaf</dt>\n",
       "\t\t<dd>3</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$boosting] 'gbdt'\n",
       "\\item[\\$objective] 'binary'\n",
       "\\item[\\$metric] 'auc'\n",
       "\\item[\\$first\\_metric\\_only] FALSE\n",
       "\\item[\\$boost\\_from\\_average] TRUE\n",
       "\\item[\\$feature\\_pre\\_filter] FALSE\n",
       "\\item[\\$force\\_row\\_wise] TRUE\n",
       "\\item[\\$verbosity] -100\n",
       "\\item[\\$seed] 102191\n",
       "\\item[\\$max\\_depth] -1\n",
       "\\item[\\$min\\_gain\\_to\\_split] 0\n",
       "\\item[\\$min\\_sum\\_hessian\\_in\\_leaf] 0.001\n",
       "\\item[\\$lambda\\_l1] 0\n",
       "\\item[\\$lambda\\_l2] 0\n",
       "\\item[\\$max\\_bin] 31\n",
       "\\item[\\$bagging\\_fraction] 1\n",
       "\\item[\\$pos\\_bagging\\_fraction] 1\n",
       "\\item[\\$neg\\_bagging\\_fraction] 1\n",
       "\\item[\\$is\\_unbalance] FALSE\n",
       "\\item[\\$scale\\_pos\\_weight] 1\n",
       "\\item[\\$drop\\_rate] 0.1\n",
       "\\item[\\$max\\_drop] 50\n",
       "\\item[\\$skip\\_drop] 0.5\n",
       "\\item[\\$extra\\_trees] FALSE\n",
       "\\item[\\$num\\_iterations] 1895\n",
       "\\item[\\$learning\\_rate] 0.0102221811029723\n",
       "\\item[\\$feature\\_fraction] 0.977185861262148\n",
       "\\item[\\$num\\_leaves] 641\n",
       "\\item[\\$min\\_data\\_in\\_leaf] 3\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$boosting\n",
       ":   'gbdt'\n",
       "$objective\n",
       ":   'binary'\n",
       "$metric\n",
       ":   'auc'\n",
       "$first_metric_only\n",
       ":   FALSE\n",
       "$boost_from_average\n",
       ":   TRUE\n",
       "$feature_pre_filter\n",
       ":   FALSE\n",
       "$force_row_wise\n",
       ":   TRUE\n",
       "$verbosity\n",
       ":   -100\n",
       "$seed\n",
       ":   102191\n",
       "$max_depth\n",
       ":   -1\n",
       "$min_gain_to_split\n",
       ":   0\n",
       "$min_sum_hessian_in_leaf\n",
       ":   0.001\n",
       "$lambda_l1\n",
       ":   0\n",
       "$lambda_l2\n",
       ":   0\n",
       "$max_bin\n",
       ":   31\n",
       "$bagging_fraction\n",
       ":   1\n",
       "$pos_bagging_fraction\n",
       ":   1\n",
       "$neg_bagging_fraction\n",
       ":   1\n",
       "$is_unbalance\n",
       ":   FALSE\n",
       "$scale_pos_weight\n",
       ":   1\n",
       "$drop_rate\n",
       ":   0.1\n",
       "$max_drop\n",
       ":   50\n",
       "$skip_drop\n",
       ":   0.5\n",
       "$extra_trees\n",
       ":   FALSE\n",
       "$num_iterations\n",
       ":   1895\n",
       "$learning_rate\n",
       ":   0.0102221811029723\n",
       "$feature_fraction\n",
       ":   0.977185861262148\n",
       "$num_leaves\n",
       ":   641\n",
       "$min_data_in_leaf\n",
       ":   3\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$boosting\n",
       "[1] \"gbdt\"\n",
       "\n",
       "$objective\n",
       "[1] \"binary\"\n",
       "\n",
       "$metric\n",
       "[1] \"auc\"\n",
       "\n",
       "$first_metric_only\n",
       "[1] FALSE\n",
       "\n",
       "$boost_from_average\n",
       "[1] TRUE\n",
       "\n",
       "$feature_pre_filter\n",
       "[1] FALSE\n",
       "\n",
       "$force_row_wise\n",
       "[1] TRUE\n",
       "\n",
       "$verbosity\n",
       "[1] -100\n",
       "\n",
       "$seed\n",
       "[1] 102191\n",
       "\n",
       "$max_depth\n",
       "[1] -1\n",
       "\n",
       "$min_gain_to_split\n",
       "[1] 0\n",
       "\n",
       "$min_sum_hessian_in_leaf\n",
       "[1] 0.001\n",
       "\n",
       "$lambda_l1\n",
       "[1] 0\n",
       "\n",
       "$lambda_l2\n",
       "[1] 0\n",
       "\n",
       "$max_bin\n",
       "[1] 31\n",
       "\n",
       "$bagging_fraction\n",
       "[1] 1\n",
       "\n",
       "$pos_bagging_fraction\n",
       "[1] 1\n",
       "\n",
       "$neg_bagging_fraction\n",
       "[1] 1\n",
       "\n",
       "$is_unbalance\n",
       "[1] FALSE\n",
       "\n",
       "$scale_pos_weight\n",
       "[1] 1\n",
       "\n",
       "$drop_rate\n",
       "[1] 0.1\n",
       "\n",
       "$max_drop\n",
       "[1] 50\n",
       "\n",
       "$skip_drop\n",
       "[1] 0.5\n",
       "\n",
       "$extra_trees\n",
       "[1] FALSE\n",
       "\n",
       "$num_iterations\n",
       "[1] 1895\n",
       "\n",
       "$learning_rate\n",
       "[1] 0.01022218\n",
       "\n",
       "$feature_fraction\n",
       "[1] 0.9771859\n",
       "\n",
       "$num_leaves\n",
       "[1] 641\n",
       "\n",
       "$min_data_in_leaf\n",
       "[1] 3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
    "  PARAM$out$lgbm$mejores_hiperparametros)\n",
    "\n",
    "param_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZIYn4l95TBH"
   },
   "source": [
    "#### Training\n",
    "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria y mucho menos cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "vPLsd4mMRe4u"
   },
   "outputs": [],
   "source": [
    "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
    "\n",
    "param_normalizado <- copy(param_final)\n",
    "param_normalizado$min_data_in_leaf <-  round(param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "WRI_-taRwOXO"
   },
   "outputs": [],
   "source": [
    "# entreno LightGBM\n",
    "\n",
    "modelo_final <- lgb.train(\n",
    "  data= dtrain_final,\n",
    "  param= param_normalizado\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "_bkhnCvj0g3Q"
   },
   "outputs": [],
   "source": [
    "# ahora imprimo la importancia de variables\n",
    "\n",
    "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
    "archivo_importancia <- \"impo.txt\"\n",
    "\n",
    "fwrite(tb_importancia,\n",
    "  file= archivo_importancia,\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "lZ3sLmbh0kFj"
   },
   "outputs": [],
   "source": [
    "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
    "lgb.save(modelo_final, \"modelo.txt\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEtp2--t5Ymg"
   },
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hI5008Mj5ZdI"
   },
   "source": [
    "Aplico el modelo final a los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "PimBY3N_0ryP"
   },
   "outputs": [],
   "source": [
    "# aplico el modelo a los datos sin clase\n",
    "dfuture <- dataset[foto_mes %in% PARAM$future]\n",
    "\n",
    "# aplico el modelo a los datos nuevos\n",
    "prediccion <- predict(\n",
    "  modelo_final,\n",
    "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "M9_NCquymhtF"
   },
   "outputs": [],
   "source": [
    "# inicilizo el dataset  drealidad\n",
    "drealidad <- realidad_inicializar( dfuture, PARAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D26rNRh55gpw"
   },
   "source": [
    "#### Tabla Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "RJwg7LHd11yu"
   },
   "outputs": [],
   "source": [
    "# tabla de prediccion\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes)]\n",
    "tb_prediccion[, prob := prediccion ]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOt4eG_55ltv"
   },
   "source": [
    "Kaggle Competition Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Vdu3moTfJ1Vl"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>9000</li><li>9500</li><li>10000</li><li>10500</li><li>11000</li><li>11500</li><li>12000</li><li>12500</li><li>13000</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 9000\n",
       "\\item 9500\n",
       "\\item 10000\n",
       "\\item 10500\n",
       "\\item 11000\n",
       "\\item 11500\n",
       "\\item 12000\n",
       "\\item 12500\n",
       "\\item 13000\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 9000\n",
       "2. 9500\n",
       "3. 10000\n",
       "4. 10500\n",
       "5. 11000\n",
       "6. 11500\n",
       "7. 12000\n",
       "8. 12500\n",
       "9. 13000\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  9000  9500 10000 10500 11000 11500 12000 12500 13000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PARAM$cortes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "gWW3tatE12je"
   },
   "outputs": [],
   "source": [
    "# genero archivos con los  \"envios\" mejores\n",
    "# suba TODOS los archivos a Kaggle\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "dir.create(\"kaggle\")\n",
    "\n",
    "for (envios in PARAM$cortes) {\n",
    "\n",
    "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
    "  tb_prediccion[1:envios, Predicted := 1L] # marco los primeros\n",
    "\n",
    "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "\n",
    "  # grabo el archivo\n",
    "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "    file= archivo_kaggle,\n",
    "    sep= \",\"\n",
    "  )\n",
    "\n",
    "  # res <- realidad_evaluar( drealidad, tb_prediccion)\n",
    "\n",
    "  # options(scipen = 999)\n",
    "  # cat( \"Envios=\", envios, \"\\t\",\n",
    "  #  \" TOTAL=\", res$total,\n",
    "  #  \"  Public=\", res$public,\n",
    "  #  \" Private=\", res$private,\n",
    "  #  \"\\n\",\n",
    "  #  sep= \"\"\n",
    "  # )\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "B9tB2X4439Hg"
   },
   "outputs": [],
   "source": [
    "write_yaml( PARAM, file=\"PARAM.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "9zA_W25c15DP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Thu Oct 02 16:18:21 2025'"
      ],
      "text/latex": [
       "'Thu Oct 02 16:18:21 2025'"
      ],
      "text/markdown": [
       "'Thu Oct 02 16:18:21 2025'"
      ],
      "text/plain": [
       "[1] \"Thu Oct 02 16:18:21 2025\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdVZucdLHzZ0"
   },
   "source": [
    "Finalmente usted deberá cargar el resultado de su corrida en la Google Sheet Colaborativa,  hoja **TareaHogar04**\n",
    "<br> Siéntase libre de agregar las columnas que hagan falta a la planilla"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
