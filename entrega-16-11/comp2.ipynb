{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SdedseitehCB",
    "outputId": "a178b9dc-dffb-48d3-83f9-4e275f6009a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna==3.6.1\n",
      "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from optuna==3.6.1) (1.16.5)\n",
      "Requirement already satisfied: colorlog in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from optuna==3.6.1) (6.9.0)\n",
      "Requirement already satisfied: numpy in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from optuna==3.6.1) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from optuna==3.6.1) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from optuna==3.6.1) (2.0.43)\n",
      "Requirement already satisfied: tqdm in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from optuna==3.6.1) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from optuna==3.6.1) (6.0.3)\n",
      "Requirement already satisfied: Mako in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from alembic>=1.5.0->optuna==3.6.1) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from alembic>=1.5.0->optuna==3.6.1) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from sqlalchemy>=1.3.0->optuna==3.6.1) (3.2.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/tomas_freilij/.venv/lib/python3.13/site-packages (from Mako->alembic>=1.5.0->optuna==3.6.1) (3.0.3)\n",
      "Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "Installing collected packages: optuna\n",
      "  Attempting uninstall: optuna\n",
      "    Found existing installation: optuna 4.5.0\n",
      "    Uninstalling optuna-4.5.0:\n",
      "      Successfully uninstalled optuna-4.5.0\n",
      "Successfully installed optuna-3.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna==3.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DYe5jnNwmZQ1"
   },
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZ8cOhJqcz6X",
    "outputId": "e25e6120-eb18-4e0e-8023-7aa2817362f4"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# src/optimization.py (actualizar)\n",
    "from token import SEMI\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4ZhveGtCdOab"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "dataset_path = './'\n",
    "modelos_directory = './'\n",
    "csv = \"competencia_02_fe.csv\"\n",
    "sufix = \"us-0-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "c4WXDjEtc1dV"
   },
   "outputs": [],
   "source": [
    "## VARIABLES DE ENTORNO Y CONFIGURACION\n",
    "MES_TRAIN = [202002,202003, 202004, 202005, 202006, 202007, 202008, 202009, 202010,202011,202012,202101]\n",
    "IS_EXPERIMENTO = False\n",
    "MES_VALIDACION = 202102\n",
    "STUDY_NAME = \"study-comp2-us-0-1-vieja-opt\"\n",
    "GANANCIA_ACIERTO = 780000\n",
    "COSTO_ESTIMULO = 20000\n",
    "FINAL_PREDICT = 202108\n",
    "MES_TEST = 202103\n",
    "FINAL_TRAIN = [202003, 202004, 202005,202006, 202007, 202008, 202009, 202010,202011,202012, 202101,202102,202103,202104,202105,202106]\n",
    "SEMILLA = [50,100,150,400,700,1000,1500,2000,3000,4000,5000,10000,15000,20000,25000]\n",
    "UNDERSAMPLE_FRACTION = 0.1\n",
    "RUN_BAYESIAN_OPTIMIZATION = False\n",
    "N_TRIALS = 30\n",
    "APLICAR_UNDERSAMPLING= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5K0uJcq-dyPi"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "def drop_columns(df : pl.DataFrame):\n",
    "\n",
    "    col_drops = [\"Visa_Finiciomora\",\"Visa_Finiciomora\",\n",
    "          \"Visa_fultimo_cierre\", \"Master_fultimo_cierre\",\n",
    "          \"Visa_Fvencimiento\", \"Master_Fvencimiento\",'tmobile_app','mprestamos_personales','cprestamos_personales'\n",
    "      ]\n",
    "\n",
    "    if \"Master_Finiciomora\" in df.columns:\n",
    "      col_drops.append(\"Master_Finiciomora\")\n",
    "\n",
    "    df = df.drop(col_drops)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pTv55YqOgP4f"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "\n",
    "\n",
    "def ganancia_optima_idealizada(df :pl.DataFrame, ternaria : pl.Series) -> float:\n",
    "\n",
    "  df_ganancias = df.hstack(ternaria.to_frame())\n",
    "  df_ganancias = df_ganancias.with_columns(\n",
    "      pl.when(pl.col('clase_ternaria').is_in([\"BAJA+2\"]))\n",
    "        .then(780000)\n",
    "        .alias('ganancia_individual')\n",
    "  )\n",
    "\n",
    "  ganancia = df_ganancias['ganancia_individual'].sum()\n",
    "  return ganancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tWCDwubygSjn"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "def undersample_df(df: pl.DataFrame, fraction) -> pl.DataFrame:\n",
    "  clientes_solo_continuas = df.group_by(\"numero_de_cliente\").agg(n_bajas=pl.col(\"clase_binaria\").sum()).filter(pl.col(\"n_bajas\") == 0)\n",
    "  clientes_solo_continuas_undersampled = clientes_solo_continuas.sample(fraction=1-fraction, seed=1000)\n",
    "  df = df.filter(~pl.col('numero_de_cliente').is_in(clientes_solo_continuas_undersampled[\"numero_de_cliente\"]))\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6mI03FVZgb4g"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "def generate_clase_peso(df : pl.DataFrame):\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.lit(1.0).alias('clase_peso')\n",
    "    ).with_columns(\n",
    "        pl.when(pl.col('clase_ternaria') == 'BAJA+2')\n",
    "        .then(pl.lit(1.00002))\n",
    "        .otherwise(pl.col('clase_peso'))\n",
    "        .alias('clase_peso')\n",
    "    ).with_columns(\n",
    "        pl.when(pl.col('clase_ternaria') == 'BAJA+1')\n",
    "        .then(pl.lit(1.00001))\n",
    "        .otherwise(pl.col('clase_peso'))\n",
    "        .alias('clase_peso')\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "## SE BINARIZA LA CLASE OBJETIVO.\n",
    "def generate_clase_binaria(df : pl.DataFrame):\n",
    "\n",
    "    df = df.with_columns(pl.lit(0).alias('clase_binaria'))\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col('clase_ternaria').is_in(['BAJA+2'])).then(pl.lit(1)).otherwise(pl.lit(0)).alias('clase_binaria')\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crudo = pl.read_csv(os.path.join(csv), infer_schema_length=None)\n",
    "df_crudo = df_crudo.sort(by=[\"numero_de_cliente\", \"foto_mes\"], descending=[False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Zirt-GdAhuvs"
   },
   "outputs": [],
   "source": [
    "df = generate_clase_peso(df_crudo)\n",
    "df = generate_clase_binaria(df)\n",
    "df = drop_columns(df)\n",
    "\n",
    "df_base_train_optuna = df.filter(pl.col('foto_mes').is_in(MES_TRAIN))\n",
    "if APLICAR_UNDERSAMPLING:\n",
    "  df_base_train_optuna = undersample_df(df_base_train_optuna, UNDERSAMPLE_FRACTION)\n",
    "\n",
    "df_train_for_optuna_targets = df_base_train_optuna.select(['numero_de_cliente', 'clase_binaria','clase_peso'])\n",
    "df_train_for_optuna_features = df_base_train_optuna.drop(['numero_de_cliente', 'clase_binaria','clase_peso','foto_mes',\"clase_ternaria\"])\n",
    "\n",
    "# --- Prepare data for final model testing/training (MES_TRAIN, always full size) ---\n",
    "df_base_train_full = df.filter(pl.col('foto_mes').is_in(MES_TRAIN))\n",
    "df_train_for_testing_targets = df_base_train_full.select(['numero_de_cliente', 'clase_binaria','clase_peso'])\n",
    "df_train_for_testing_features = df_base_train_full.drop(['numero_de_cliente', 'clase_binaria','clase_peso','foto_mes',\"clase_ternaria\"])\n",
    "\n",
    "\n",
    "# MES_TEST, FINAL_PREDICT, FINAL_TRAIN, MES_VALIDACION)\n",
    "df_test_base = df.filter(pl.col('foto_mes') == MES_TEST)\n",
    "df_test_with_target = df_test_base.select(['numero_de_cliente', 'clase_binaria','clase_peso', \"clase_ternaria\"])\n",
    "df_test_features = df_test_base.drop(['clase_binaria','clase_peso','foto_mes',\"clase_ternaria\"])\n",
    "\n",
    "df_predict_base = df.filter(pl.col('foto_mes') == FINAL_PREDICT)\n",
    "df_predict_with_target = df_predict_base.select(['numero_de_cliente'])\n",
    "if IS_EXPERIMENTO:\n",
    "  df_predict_with_target = df_predict_base.select(['numero_de_cliente', 'clase_binaria','clase_peso','clase_ternaria'])\n",
    "  df_predict_features = df_predict_base.drop(['clase_binaria','clase_peso','foto_mes',\"clase_ternaria\"])\n",
    "else:\n",
    "  df_predict_features = df_predict_base.drop(['clase_binaria','clase_peso','foto_mes',\"clase_ternaria\"])\n",
    "\n",
    "df_train_predict_base = df.filter(pl.col('foto_mes').is_in(FINAL_TRAIN))\n",
    "df_train_predict_with_target = df_train_predict_base.select(['numero_de_cliente', 'clase_binaria','clase_peso'])\n",
    "df_train_predict_features = df_train_predict_base.drop(['numero_de_cliente','clase_binaria','clase_peso','foto_mes',\"clase_ternaria\"])\n",
    "\n",
    "#df_val_base = df.filter(pl.col('foto_mes') == MES_VALIDACION)\n",
    "#df_val_with_target = df_val_base.select(['numero_de_cliente', 'clase_binaria','clase_peso'])\n",
    "#df_val_features = df_val_base.drop(['clase_binaria','clase_peso','foto_mes',\"clase_ternaria\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellView": "form",
    "id": "MiIoHuQbgN2Q"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "## SE ARMAN LAS PREDICCIONES PROMEDIADAS\n",
    "def build_predictions(modelos, dataset : pl.DataFrame) -> pl.DataFrame:\n",
    "  predicciones = {}\n",
    "\n",
    "  # Sort the dataset by numero_de_cliente to ensure consistent order\n",
    "  dataset = dataset.sort(\"numero_de_cliente\")\n",
    "\n",
    "  clientes = dataset[\"numero_de_cliente\"]\n",
    "  df_to_predict = dataset.drop([\"numero_de_cliente\"])\n",
    "\n",
    "  # Convert the dataset to a NumPy array for LightGBM prediction\n",
    "  dataset_np = df_to_predict.to_numpy()\n",
    "\n",
    "  for seed,model in modelos.items():\n",
    "    if seed in SEMILLA:\n",
    "      predictions = model.predict(dataset_np)\n",
    "      predicciones[seed] = predictions\n",
    "\n",
    "  mean_predictions = np.mean(list(predicciones.values()), axis=0)\n",
    "  return pl.DataFrame({'numero_de_cliente': clientes, 'Predicted': mean_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "eVQTZz0IB53t"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "def lgb_gan_eval(y_pred, data: lgb.Dataset):\n",
    "  weight = data.get_weight()\n",
    "\n",
    "  ganancia = np.where(weight == 1.00002, GANANCIA_ACIERTO, 0) - np.where(\n",
    "      weight < 1.00002, COSTO_ESTIMULO, 0\n",
    "  )\n",
    "\n",
    "  ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "  ganancia = np.cumsum(ganancia)\n",
    "\n",
    "  return \"gan_eval\", float(np.max(ganancia)), True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CuSdOSvFgvSq",
    "outputId": "c8f2980d-b624-4264-b02c-d5193fec0e1b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 21:44:43,022] Using an existing study with name 'study-comp2-us-0-1-vieja-opt' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "# @title\n",
    "def objective(trial) -> float:\n",
    "\n",
    "    logger.info(f\"Begin Trial {trial.number}\")\n",
    "    num_leaves = trial.suggest_int('num_leaves', 8, 80)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.4)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 10, 100)\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 1000)\n",
    "    feature_fraction = trial.suggest_float('feature_fraction', 0.1, 1.0)\n",
    "    max_bin = trial.suggest_int('max_bin', 255, 500)\n",
    "    num_iterations = trial.suggest_int('num_iterations', 100, 500)\n",
    "\n",
    "    logger.info(f\"Opt Train Data : {len(df_train_for_optuna_features.columns)} , {df_train_for_optuna_targets[\"clase_binaria\"].shape} , {df_train_for_optuna_targets[\"clase_peso\"].shape}\")\n",
    "    opt_train_pd = df_train_for_optuna_features.to_numpy()\n",
    "    opt_y_pd = df_train_for_optuna_targets[\"clase_binaria\"].to_numpy()\n",
    "    opt_weight_pd = df_train_for_optuna_targets[\"clase_peso\"].to_numpy()\n",
    "\n",
    "    train_data = lgb.Dataset(opt_train_pd,\n",
    "                                label=opt_y_pd,\n",
    "                                weight=opt_weight_pd)\n",
    "\n",
    "    #opt_X_val_pd = df_val_features.to_numpy()\n",
    "    #opt_y_val_pd = df_val_with_target[\"clase_binaria\"].to_numpy()\n",
    "    #weight_val_pd = df_val_with_target[\"clase_peso\"].to_numpy()\n",
    "    #val_data = lgb.Dataset(opt_X_val_pd,label=opt_y_val_pd,weight=weight_val_pd)\n",
    "\n",
    "    modelos = {}\n",
    "    params = {\n",
    "      'objective': 'binary',\n",
    "      'metric': 'custom',\n",
    "      'boosting_type': 'rf',\n",
    "      'first_metric_only': True,\n",
    "      'boost_from_average': True,\n",
    "      'feature_pre_filter': False,\n",
    "      'max_bin': max_bin,\n",
    "      'max_depth': max_depth,\n",
    "      'num_leaves': num_leaves,\n",
    "      'learning_rate': learning_rate,\n",
    "      'min_data_in_leaf': min_data_in_leaf,\n",
    "      'feature_fraction': feature_fraction,\n",
    "      'seed': SEMILLA[1],\n",
    "      'verbose': -1,\n",
    "      'num_iterations': num_iterations\n",
    "      }\n",
    "\n",
    "    cv_results = lgb.cv(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=110,\n",
    "        callbacks=[lgb.early_stopping( int((50 + 5) / learning_rate))],\n",
    "        feval=lgb_gan_eval,\n",
    "        stratified=True,\n",
    "        nfold=5\n",
    "    )\n",
    "    max_gan = np.mean(cv_results['valid gan_eval-mean'])\n",
    "    best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n",
    "\n",
    "    trial.set_user_attr(\"best_iter\", best_iter)\n",
    "\n",
    "    return max_gan\n",
    "\n",
    "\n",
    "# SE INTENTA RECUPERAR UN ESTUDIO O SE INICIA UNO NUEVO\n",
    "#storage_name = f\"sqlite:////{os.path.join(BUCKETS, BUCKET_TARGET,STUDY_NAME)}.db\"\n",
    "storage_name = f\"sqlite:///{os.path.join(modelos_directory,STUDY_NAME)}.db\"\n",
    "study_name = STUDY_NAME\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# HAY UN FLAG EN EL CONFIG PARA EVITAR CORRER LA OPTIMIZACION SIEMPRE\n",
    "if RUN_BAYESIAN_OPTIMIZATION:\n",
    "  logger.info(f\"Run Optimization with {N_TRIALS}\")\n",
    "  # Pass the training data explicitly to the objective function\n",
    "  study.optimize(lambda trial: objective(trial), n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cellView": "form",
    "id": "ctajKctghp4t"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "\n",
    "## SE ARMA EL MODELO Y DE SER POSIBLE SE PERSISTE PARA PODER USARLO PARA OTRA PREDICCION.\n",
    "def build_and_save_or_load_models(study, semillas : list, train_dataset : pl.DataFrame, y_target : pl.DataFrame, undersampling_fraction, is_test, is_final=False) -> dict:\n",
    "\n",
    "  modelos = {}\n",
    "  if is_test:\n",
    "    sufix = \"test\"\n",
    "  else:\n",
    "    if not is_final:\n",
    "        sufix = \"final\"\n",
    "    else:\n",
    "        sufix = \"predict\"\n",
    "\n",
    "  all_models_exist = True\n",
    "  for seed in SEMILLA:\n",
    "    model_name = f\"lgb_predict_{seed}_{sufix}.txt\"\n",
    "    model_file_path = os.path.join(modelos_directory, model_name)\n",
    "    if not os.path.exists(model_file_path):\n",
    "      all_models_exist = False\n",
    "      break\n",
    "\n",
    "  if all_models_exist:\n",
    "    for seed in SEMILLA:\n",
    "        model_name = f\"lgb_predict_{seed}_{sufix}.txt\"\n",
    "        model_file_path = os.path.join(modelos_directory, model_name)\n",
    "        modelos[seed] = lgb.Booster(model_file=model_file_path)\n",
    "  else:\n",
    "    train_dataset_pd = train_dataset.to_pandas()\n",
    "    y_target_np = y_target[\"clase_binaria\"].to_numpy()\n",
    "    weight_np = y_target[\"clase_peso\"].to_numpy()\n",
    "\n",
    "    train_data = lgb.Dataset(train_dataset_pd,\n",
    "                                label=y_target_np,\n",
    "                                weight=weight_np)\n",
    "\n",
    "    if len(study.trials) == 0:\n",
    "      raise RuntimeError(\"No trials found in study. Run optimization first.\")\n",
    "\n",
    "    best_params = study.best_trial.params.copy()\n",
    "    best_num_boost_round = study.best_trial.user_attrs.get(\"best_iter\", 110)\n",
    "\n",
    "    # Remove 'num_iterations' from best_params as we use best_num_boost_round\n",
    "    if 'num_iterations' in best_params:\n",
    "        del best_params['num_iterations']\n",
    "\n",
    "\n",
    "    best_params['min_data_in_leaf'] = int(best_params['min_data_in_leaf']*80 / undersampling_fraction)\n",
    "\n",
    "    for seed in semillas:\n",
    "      params = {\n",
    "              'objective': 'binary',\n",
    "                'metric': 'custom',\n",
    "                'boosting_type': 'rf',\n",
    "                'first_metric_only': True,\n",
    "                'boost_from_average': True,\n",
    "                'feature_pre_filter': False,\n",
    "                'seed': seed,\n",
    "                'verbose': -1,\n",
    "                **best_params\n",
    "          }\n",
    "\n",
    "      model = lgb.train(params, train_data, num_boost_round=best_num_boost_round)\n",
    "\n",
    "      modelos[seed] = model\n",
    "      model.save_model(os.path.join(modelos_directory,f\"lgb_predict_{seed}_{sufix}.txt\"))\n",
    "\n",
    "  return modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cellView": "form",
    "id": "8C2JX8HPgRPv"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "\n",
    "\n",
    "def build_final_predictions(predict_models, df_predict, n_envios):\n",
    "  mean_predictions = build_predictions(predict_models, df_predict)\n",
    "  sorted_mean_predictions = mean_predictions.sort('Predicted', descending=True)\n",
    "  final_predictions = sorted_mean_predictions.with_columns(\n",
    "        (pl.arange(0, sorted_mean_predictions.height) < n_envios)\n",
    "        .cast(pl.Int8)\n",
    "        .alias(\"Predicted\")\n",
    "    )\n",
    "\n",
    "  return final_predictions.select([\"numero_de_cliente\", \"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cellView": "form",
    "id": "WxO7a7dwU6n3"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "def cantidad_envios(y_pred : pl.DataFrame, y_true : pl.DataFrame) -> float:\n",
    "    df_eval = y_pred.join(y_true, on=\"numero_de_cliente\")\n",
    "    print(df_eval)\n",
    "    df_ordenado = df_eval.sort(\"Predicted\", descending=True)\n",
    "\n",
    "    # Ganancia individual por fila, cast to Float64 to prevent potential overflow\n",
    "    df_ordenado = df_ordenado.with_columns([\n",
    "        pl.when(pl.col(\"clase_binaria\") == 1)\n",
    "          .then(pl.lit(GANANCIA_ACIERTO).cast(pl.Float64))\n",
    "          .otherwise(pl.lit(-COSTO_ESTIMULO).cast(pl.Float64))\n",
    "          .alias(\"ganancia_individual\")\n",
    "    ])\n",
    "\n",
    "    # Ganancia acumulada\n",
    "    df_ordenado = df_ordenado.with_columns([\n",
    "        pl.col(\"ganancia_individual\").cum_sum().alias(\"ganancia_acumulada\")\n",
    "    ])\n",
    "\n",
    "    # Obtener ganancia maxima\n",
    "    ganancia_maxima = df_ordenado.select(pl.col(\"ganancia_acumulada\").max()).item()\n",
    "\n",
    "    # Find the index of the first occurrence of the maximum cumulative gain\n",
    "    idx_max_ganancia = df_ordenado[\"ganancia_acumulada\"].arg_max()\n",
    "\n",
    "    # The number of sends is the index + 1 (since index is 0-based)\n",
    "    cantidad_envios_real = idx_max_ganancia + 1\n",
    "\n",
    "    return float(ganancia_maxima), cantidad_envios_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NdhmPB3cTsu6",
    "outputId": "68b6d5fe-d81c-4a3a-cdf8-5b7924b0e004"
   },
   "outputs": [],
   "source": [
    "test_models = build_and_save_or_load_models(study, SEMILLA, df_train_for_testing_features, df_train_for_testing_targets, undersampling_fraction=UNDERSAMPLE_FRACTION, is_test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "-OOKtuUk4SQ-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ganancia 'optima idealizada' en Prediccion usada como pruebas: 741000000\n",
      "Clases ternarias en Test: shape: (3, 2)\n",
      "┌────────────────┬────────┐\n",
      "│ clase_ternaria ┆ count  │\n",
      "│ ---            ┆ ---    │\n",
      "│ str            ┆ u32    │\n",
      "╞════════════════╪════════╡\n",
      "│ BAJA+2         ┆ 950    │\n",
      "│ BAJA+1         ┆ 1027   │\n",
      "│ CONTINUA       ┆ 161132 │\n",
      "└────────────────┴────────┘\n",
      "shape: (163_109, 5)\n",
      "┌───────────────────┬───────────┬───────────────┬────────────┬────────────────┐\n",
      "│ numero_de_cliente ┆ Predicted ┆ clase_binaria ┆ clase_peso ┆ clase_ternaria │\n",
      "│ ---               ┆ ---       ┆ ---           ┆ ---        ┆ ---            │\n",
      "│ i64               ┆ f64       ┆ i32           ┆ f64        ┆ str            │\n",
      "╞═══════════════════╪═══════════╪═══════════════╪════════════╪════════════════╡\n",
      "│ 249221323         ┆ 0.002044  ┆ 0             ┆ 1.0        ┆ CONTINUA       │\n",
      "│ 249227600         ┆ 0.001356  ┆ 0             ┆ 1.0        ┆ CONTINUA       │\n",
      "│ 249234235         ┆ 0.017435  ┆ 0             ┆ 1.0        ┆ CONTINUA       │\n",
      "│ 249244449         ┆ 0.001863  ┆ 0             ┆ 1.0        ┆ CONTINUA       │\n",
      "│ 249244739         ┆ 0.001851  ┆ 0             ┆ 1.0        ┆ CONTINUA       │\n",
      "│ …                 ┆ …         ┆ …             ┆ …          ┆ …              │\n",
      "│ 1589499629        ┆ 0.017705  ┆ 0             ┆ 1.0        ┆ CONTINUA       │\n",
      "│ 1589500209        ┆ 0.017468  ┆ 0             ┆ 1.0        ┆ CONTINUA       │\n",
      "│ 1589507434        ┆ 0.021195  ┆ 0             ┆ 1.0        ┆ CONTINUA       │\n",
      "│ 1589582985        ┆ 0.021195  ┆ 0             ┆ 1.0        ┆ CONTINUA       │\n",
      "│ 1589611354        ┆ 0.021195  ┆ 0             ┆ 1.0        ┆ CONTINUA       │\n",
      "└───────────────────┴───────────┴───────────────┴────────────┴────────────────┘\n",
      "Ganancia en Prediccion de Experimento : 159540000.0 con 11703 envios\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if \"clase_ternaria\" in df_test_with_target.columns:\n",
    "  df_test_ternaria = df_test_with_target[\"clase_ternaria\"]\n",
    "  log = f\"Ganancia 'optima idealizada' en Prediccion usada como pruebas: {ganancia_optima_idealizada(df_test_features, df_test_ternaria)}\"\n",
    "print(log)\n",
    "log = f\"Clases ternarias en Test: {df_test_ternaria.value_counts()}\"\n",
    "print(log)\n",
    "\n",
    "# The columns to drop from df_test_features are already dropped when df_test_features was created.\n",
    "# comp_predictions = build_predictions(test_models, df_test) # Original line\n",
    "comp_predictions = build_predictions(test_models, df_test_features)\n",
    "ganancia, n_envios_final = cantidad_envios(comp_predictions, df_test_with_target)\n",
    "print(f\"Ganancia en Prediccion de Experimento : {ganancia} con {n_envios_final} envios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "fAKA7FonT8Nm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_842, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>numero_de_cliente</th><th>Predicted</th></tr><tr><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>249654219</td><td>0.998332</td></tr><tr><td>249809121</td><td>0.770113</td></tr><tr><td>250130651</td><td>0.742283</td></tr><tr><td>250211454</td><td>1.0</td></tr><tr><td>250371967</td><td>0.955707</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1548033591</td><td>0.885683</td></tr><tr><td>1558353134</td><td>0.595546</td></tr><tr><td>1558597439</td><td>0.655407</td></tr><tr><td>1559900287</td><td>0.592469</td></tr><tr><td>1574841798</td><td>0.820354</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_842, 2)\n",
       "┌───────────────────┬───────────┐\n",
       "│ numero_de_cliente ┆ Predicted │\n",
       "│ ---               ┆ ---       │\n",
       "│ i64               ┆ f64       │\n",
       "╞═══════════════════╪═══════════╡\n",
       "│ 249654219         ┆ 0.998332  │\n",
       "│ 249809121         ┆ 0.770113  │\n",
       "│ 250130651         ┆ 0.742283  │\n",
       "│ 250211454         ┆ 1.0       │\n",
       "│ 250371967         ┆ 0.955707  │\n",
       "│ …                 ┆ …         │\n",
       "│ 1548033591        ┆ 0.885683  │\n",
       "│ 1558353134        ┆ 0.595546  │\n",
       "│ 1558597439        ┆ 0.655407  │\n",
       "│ 1559900287        ┆ 0.592469  │\n",
       "│ 1574841798        ┆ 0.820354  │\n",
       "└───────────────────┴───────────┘"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_predictions.filter(pl.col(\"Predicted\") > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_models = build_and_save_or_load_models(study, SEMILLA,df_train_predict_features, df_train_predict_with_target, undersampling_fraction=UNDERSAMPLE_FRACTION, is_test = False, is_final=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "OniyxM8OhY1o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11703\n",
      "Predecimos 202108\n",
      "Entrenamos [202003, 202004, 202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012, 202101, 202102, 202103, 202104, 202105, 202106]\n",
      "Terminó el programa\n"
     ]
    }
   ],
   "source": [
    "# Retrieve best n_envios from the study's best trial\n",
    "print(n_envios_final)\n",
    "print(f\"Predecimos {FINAL_PREDICT}\")\n",
    "print(f\"Entrenamos {FINAL_TRAIN}\")\n",
    "\n",
    "\n",
    "\n",
    "if IS_EXPERIMENTO:\n",
    "  if \"clase_ternaria\" in df_predict_with_target.columns:\n",
    "    df_predict_ternaria = df_predict_with_target[\"clase_ternaria\"]\n",
    "    log = f\"Ganancia 'optima idealizada' en Prediccion usada como pruebas: {ganancia_optima_idealizada(df_predict_features, df_predict_ternaria)}\"\n",
    "    logger.info(log)\n",
    "    print(log)\n",
    "    log = f\"Clases ternarias en Prediccion: {df_predict_ternaria.value_counts()}\"\n",
    "    logger.info(log)\n",
    "    print(log)\n",
    "\n",
    "  # The columns to drop are already handled when df_predict_features was created\n",
    "  # if cols_to_drop:\n",
    "  #   logger.info(f\"Dropping columns from df_predict: {cols_to_drop}\")\n",
    "  #   print(f\"Dropping columns from df_predict: {cols_to_drop}\")\n",
    "  #   df_predict = df_predict.drop(cols_to_drop)\n",
    "\n",
    "  comp_predictions = build_final_predictions(predict_models, df_predict_features, n_envios_final)\n",
    "  print(comp_predictions[\"Predicted\"].value_counts())\n",
    "  ganancia, n_envios_final = cantidad_envios(comp_predictions, df_predict_with_target)\n",
    "  logger.info(f\"Ganancia en Prediccion de Experimento : {ganancia} con {n_envios_final} envios\")\n",
    "  print(f\"Ganancia en Prediccion de Experimento : {ganancia} con {n_envios_final} envios\")\n",
    "\n",
    "  print(f\"Forzando n_envios {forzar_n_envios(comp_predictions, df_predict_with_target, best_n_envios)}\")\n",
    "\n",
    "\n",
    "else:\n",
    "\n",
    "  # The columns to drop are already handled when df_predict_features was created\n",
    "  # if cols_to_drop:\n",
    "  #   logger.info(f\"Dropping columns from df_predict: {cols_to_drop}\")\n",
    "  #   df_predict = df_predict.drop(cols_to_drop)\n",
    "\n",
    "  #prediction_path = os.path.join(BUCKETS, BUCKET_TARGET, f\"predictions.csv\")\n",
    "  prediction_path = \"predictions.csv\"\n",
    "  comp_predictions = build_final_predictions(predict_models, df_predict_features, n_envios_final)\n",
    "  comp_predictions.write_csv(prediction_path)\n",
    "\n",
    "print(\"Terminó el programa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rSgxoISo7FV"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lgb.plot_importance(predict_models[50], figsize=(30, 40))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
